{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict, deque\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import skew\n",
    "\n",
    "import feather\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from concurrent import futures\n",
    "#import riiideducation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyaka1 = np.load(\"./ssakt15_valid_preds.npy\")\n",
    "lyaka2 = np.load(\"./ssakt31_valid_preds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sakami = pd.read_csv(\"./sakami-1221.csv\")\n",
    "sakami2 = np.load(\"./sakami-134pp.npy\")\n",
    "sakami[\"sakami2\"] = sakami2\n",
    "sakami[\"lyaka1\"] = lyaka1\n",
    "sakami[\"lyaka2\"] = lyaka2\n",
    "pocket_1221 = pd.read_csv(\"./pred_1221.csv\")\n",
    "pocket_1223 = pd.read_csv(\"./pred_1223.csv\")\n",
    "pocket_1226 = pd.read_csv(\"./pred_1226.csv\")\n",
    "owruby = pd.read_csv(\"./owruby_v022.csv\")\n",
    "owruby2_1 = pd.read_csv(\"./owruby_v026_1.csv\")\n",
    "owruby2_2 = pd.read_csv(\"./owruby_v026_2.csv\")\n",
    "owruby2_3 = pd.read_csv(\"./owruby_v026_3.csv\")\n",
    "owruby2_4 = pd.read_csv(\"./owruby_v026_4.csv\")\n",
    "merged = owruby.copy()\n",
    "merged[\"pocket_1221\"] = pocket_1221\n",
    "merged[\"pocket_1223\"] = pocket_1223\n",
    "merged[\"pocket_1226\"] = pocket_1226\n",
    "merged[\"owruby\"] = merged[\"answered_correctly\"]\n",
    "merged[\"owruby2_1\"] = owruby2_1[\"answered_correctly\"]\n",
    "merged[\"owruby2_2\"] = owruby2_2[\"answered_correctly\"]\n",
    "merged[\"owruby2_3\"] = owruby2_3[\"answered_correctly\"]\n",
    "merged[\"owruby2_4\"] = owruby2_4[\"answered_correctly\"]\n",
    "merged.drop(columns=\"answered_correctly\", inplace=True)\n",
    "merged2 = pd.merge(merged, sakami, on=\"row_id\", how=\"inner\")\n",
    "merged2[\"sakami\"] = merged2[\"prediction\"]\n",
    "merged2.drop(columns=\"prediction\", inplace=True)\n",
    "merged2[\"owruby2\"] = (merged2[\"owruby2_1\"] + merged2[\"owruby2_2\"] + merged2[\"owruby2_3\"] + merged2[\"owruby2_4\"]) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_feats = pd.read_feather(\"./valid_1226.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000, 70)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([merged2, valid_feats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pocket_1221</th>\n",
       "      <th>pocket_1223</th>\n",
       "      <th>pocket_1226</th>\n",
       "      <th>owruby</th>\n",
       "      <th>owruby2_1</th>\n",
       "      <th>owruby2_2</th>\n",
       "      <th>owruby2_3</th>\n",
       "      <th>owruby2_4</th>\n",
       "      <th>...</th>\n",
       "      <th>u_td_p2p3</th>\n",
       "      <th>u_td_p3p4</th>\n",
       "      <th>u_td_p4p5</th>\n",
       "      <th>u_td_p5p6</th>\n",
       "      <th>u_td_p6p7</th>\n",
       "      <th>u_td_p7p8</th>\n",
       "      <th>u_td_p8p9</th>\n",
       "      <th>u_td_p9p10</th>\n",
       "      <th>ut_ac_mean</th>\n",
       "      <th>ut_ac_mean2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70629059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899222</td>\n",
       "      <td>0.882067</td>\n",
       "      <td>0.871062</td>\n",
       "      <td>0.851218</td>\n",
       "      <td>0.818395</td>\n",
       "      <td>0.762108</td>\n",
       "      <td>0.795984</td>\n",
       "      <td>0.824208</td>\n",
       "      <td>...</td>\n",
       "      <td>325317.0</td>\n",
       "      <td>454170.0</td>\n",
       "      <td>2732487.0</td>\n",
       "      <td>143467.0</td>\n",
       "      <td>190046.0</td>\n",
       "      <td>182226.0</td>\n",
       "      <td>190944.0</td>\n",
       "      <td>110019856.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.688819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70629060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875296</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.866829</td>\n",
       "      <td>0.832965</td>\n",
       "      <td>0.817051</td>\n",
       "      <td>0.821449</td>\n",
       "      <td>0.836079</td>\n",
       "      <td>0.826704</td>\n",
       "      <td>...</td>\n",
       "      <td>820188.0</td>\n",
       "      <td>325317.0</td>\n",
       "      <td>454170.0</td>\n",
       "      <td>2732487.0</td>\n",
       "      <td>143467.0</td>\n",
       "      <td>190046.0</td>\n",
       "      <td>182226.0</td>\n",
       "      <td>190944.0</td>\n",
       "      <td>0.737113</td>\n",
       "      <td>0.711192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70629061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.765987</td>\n",
       "      <td>0.749301</td>\n",
       "      <td>0.758079</td>\n",
       "      <td>0.835464</td>\n",
       "      <td>0.769723</td>\n",
       "      <td>0.787055</td>\n",
       "      <td>0.767097</td>\n",
       "      <td>0.817363</td>\n",
       "      <td>...</td>\n",
       "      <td>820188.0</td>\n",
       "      <td>325317.0</td>\n",
       "      <td>454170.0</td>\n",
       "      <td>2732487.0</td>\n",
       "      <td>143467.0</td>\n",
       "      <td>190046.0</td>\n",
       "      <td>182226.0</td>\n",
       "      <td>190944.0</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.688819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59577091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831968</td>\n",
       "      <td>0.776635</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.775140</td>\n",
       "      <td>0.677333</td>\n",
       "      <td>0.759442</td>\n",
       "      <td>0.770177</td>\n",
       "      <td>0.745514</td>\n",
       "      <td>...</td>\n",
       "      <td>2243661.0</td>\n",
       "      <td>657769.0</td>\n",
       "      <td>720899.0</td>\n",
       "      <td>597984.0</td>\n",
       "      <td>415187.0</td>\n",
       "      <td>527912.0</td>\n",
       "      <td>407554.0</td>\n",
       "      <td>291635.0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59577092</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924458</td>\n",
       "      <td>0.946935</td>\n",
       "      <td>0.956017</td>\n",
       "      <td>0.970708</td>\n",
       "      <td>0.957377</td>\n",
       "      <td>0.920569</td>\n",
       "      <td>0.961104</td>\n",
       "      <td>0.980009</td>\n",
       "      <td>...</td>\n",
       "      <td>56203.0</td>\n",
       "      <td>2243661.0</td>\n",
       "      <td>657769.0</td>\n",
       "      <td>720899.0</td>\n",
       "      <td>597984.0</td>\n",
       "      <td>415187.0</td>\n",
       "      <td>527912.0</td>\n",
       "      <td>407554.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  label  pocket_1221  pocket_1223  pocket_1226    owruby  \\\n",
       "0  70629059      1     0.899222     0.882067     0.871062  0.851218   \n",
       "1  70629060      1     0.875296     0.861982     0.866829  0.832965   \n",
       "2  70629061      0     0.765987     0.749301     0.758079  0.835464   \n",
       "3  59577091      1     0.831968     0.776635     0.764286  0.775140   \n",
       "4  59577092      1     0.924458     0.946935     0.956017  0.970708   \n",
       "\n",
       "   owruby2_1  owruby2_2  owruby2_3  owruby2_4  ...  u_td_p2p3  u_td_p3p4  \\\n",
       "0   0.818395   0.762108   0.795984   0.824208  ...   325317.0   454170.0   \n",
       "1   0.817051   0.821449   0.836079   0.826704  ...   820188.0   325317.0   \n",
       "2   0.769723   0.787055   0.767097   0.817363  ...   820188.0   325317.0   \n",
       "3   0.677333   0.759442   0.770177   0.745514  ...  2243661.0   657769.0   \n",
       "4   0.957377   0.920569   0.961104   0.980009  ...    56203.0  2243661.0   \n",
       "\n",
       "   u_td_p4p5  u_td_p5p6  u_td_p6p7  u_td_p7p8  u_td_p8p9   u_td_p9p10  \\\n",
       "0  2732487.0   143467.0   190046.0   182226.0   190944.0  110019856.0   \n",
       "1   454170.0  2732487.0   143467.0   190046.0   182226.0     190944.0   \n",
       "2   454170.0  2732487.0   143467.0   190046.0   182226.0     190944.0   \n",
       "3   720899.0   597984.0   415187.0   527912.0   407554.0     291635.0   \n",
       "4   657769.0   720899.0   597984.0   415187.0   527912.0     407554.0   \n",
       "\n",
       "   ut_ac_mean  ut_ac_mean2  \n",
       "0    0.705882     0.688819  \n",
       "1    0.737113     0.711192  \n",
       "2    0.705882     0.688819  \n",
       "3    0.647059     0.645833  \n",
       "4    0.750000     0.812500  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLgb:\n",
    "    def __init__(self, seed=99, dry_run=False):\n",
    "        self.train_param = self.get_param()\n",
    "        if dry_run:\n",
    "            self.num_rounds = 100\n",
    "        else:\n",
    "            self.num_rounds = 1100\n",
    "\n",
    "    def do_train_direct(self, x_train, x_test, y_train, y_test):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "        # print('Start training...')\n",
    "        model = lgb.train(self.train_param,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_eval],\n",
    "                          verbose_eval=100,\n",
    "                          num_boost_round=self.num_rounds,\n",
    "                          early_stopping_rounds=100,\n",
    "                          #categorical_feature=[]\n",
    "                         )\n",
    "        # print('End training...')\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def show_feature_importance(model, filename=None):\n",
    "        fi = pd.DataFrame({\n",
    "            \"name\": model.feature_name(),\n",
    "            \"importance_split\": model.feature_importance(importance_type=\"split\").astype(int),\n",
    "            \"importance_gain\": model.feature_importance(importance_type=\"gain\").astype(int),\n",
    "        })\n",
    "        fi = fi.sort_values(by=\"importance_gain\", ascending=False)\n",
    "        #print(fi)\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            print(fi)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_param():\n",
    "        return {\n",
    "            'num_leaves': 127,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'objective': 'binary',\n",
    "            #'metric': 'auc',\n",
    "            'metric': 'binary_logloss',\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.02,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"verbosity\": -1,\n",
    "            \"random_state\": 81,\n",
    "        }\n",
    "    \n",
    "class SingleTrainer:\n",
    "    def __init__(self, pred_col, dry_run=False):\n",
    "        self.pred_col = pred_col\n",
    "        self.target_col = \"ac\"\n",
    "        self.dry_run = dry_run\n",
    "        self.val_size = 2*1000*1000\n",
    "\n",
    "    def train_model(self, df):\n",
    "        X = df[self.pred_col]\n",
    "        y = df[self.target_col]\n",
    "        \n",
    "        models, scores = list(), list()\n",
    "        for fold in range(4):\n",
    "            print(\"---------\")\n",
    "            print(\"fold=\", fold)\n",
    "            f, c = fold, self.val_size\n",
    "            val_s, val_e = -c-f*c, len(df)-f*c\n",
    "            train_idx = -c-f*c\n",
    "            X_train, X_val = X.iloc[:train_idx], X.iloc[val_s:val_e]\n",
    "            y_train, y_val = y.iloc[:train_idx], y.iloc[val_s:val_e]\n",
    "            print(X_train.shape, X_val.shape)\n",
    "            \n",
    "            lgbm = SingleLgb(seed=99, dry_run=self.dry_run)\n",
    "            model = lgbm.do_train_direct(X_train, X_val, y_train, y_val)\n",
    "            score = model.best_score[\"valid_0\"][\"binary_logloss\"]\n",
    "            pred = model.predict(X_val)\n",
    "            score = metrics.roc_auc_score(y_val, pred)\n",
    "            print(\"AUC=\", score)\n",
    "            if fold == 0:\n",
    "                lgbm.show_feature_importance(model)\n",
    "            models.append(model)\n",
    "            scores.append(score)\n",
    "            break\n",
    "        return models, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['et', 'q_ac_cnt', 'b_ac_mean', 'b_ac_cnt', 'q_ac_mean', 'u_ac_mean', 'u_cnt', 'u_qm_mean', 'u_ac_cnt', 'u_ok_qm_mean', 'u_ng_qm_mean', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'up_ac_cnt', 'up_ac_mean', 'u_td', 'q_ng_uac_mean', 'q_ok_uac_mean', 'q_ok_uac_std', 'q_ng_uac_std', 'correct_answer', 'u_ac_mean20', 'ulr_ac_mean', 'ut_ac_mean', 'ut_ac_mean2', 'uca_ac_mean', 'ul_td', 'u_td_wl', 'uc_td', 'uc_ac_mean', 'uc_ac_cnt', 'u_td_tp1', 'u_td_p1p2', 'u_td_p2p3', 'u_td_p3p4', 'u_td_p4p5', 'u_td_p5p6', 'u_td_p6p7', 'u_td_p7p8', 'u_td_p8p9', 'u_td_p9p10', 'uac_prev1', 'uac_prev2', 'elo_beta', 'u_elo_theta', 'u_rate', 'nn_svd0', 'nn_svd1', 'nn_svd2', 'nn_svd3', 'nn_svd4', 'nn_svd5', 'nn_svd6', 'nn_svd7', 'nn_svd8', 'nn_svd9', 'nn_svd10', 'nn_svd11', 'nn_svd12', 'nn_svd13', 'nn_svd14', 'nn_svd15', 'nn_svd16', 'nn_svd17', 'nn_svd18', 'nn_svd19']\n"
     ]
    }
   ],
   "source": [
    "pred_col = [\n",
    "    \"et\",  \"q_ac_cnt\",  'b_ac_mean', 'b_ac_cnt', \"q_ac_mean\",\n",
    "    \"u_ac_mean\", \"u_cnt\", \"u_qm_mean\", #\"u_td\", #\"uc_td\",\n",
    "    \"u_ac_cnt\", #\"u_et_cnt\"\n",
    "    'u_ok_qm_mean', 'u_ng_qm_mean',\n",
    "    'q_et_mean', 'q_et_cnt', 'q_et_std',\n",
    "   \"up_ac_cnt\", \"up_ac_mean\",\n",
    "    \"u_td\", \n",
    "    \"q_ng_uac_mean\",\"q_ok_uac_mean\", \"q_ok_uac_std\", \"q_ng_uac_std\",\n",
    "    \"correct_answer\",\n",
    "    \"u_ac_mean20\",\n",
    "    \"ulr_ac_mean\", #\"ulr_ac_cnt\",  \"ub_cnt\",\n",
    "    \"ut_ac_mean\",\"ut_ac_mean2\",\n",
    "    \"uca_ac_mean\", \n",
    "    \"ul_td\", \"u_td_wl\", \n",
    "    #\"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\", \"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\",\n",
    "    #\"pqhe\",\n",
    "    \"uc_td\", \"uc_ac_mean\", \"uc_ac_cnt\", \n",
    "    #\"u_td_final\", #\"ub_td_final\"\n",
    "    'u_td_tp1','u_td_p1p2', 'u_td_p2p3', 'u_td_p3p4', 'u_td_p4p5',\n",
    "    'u_td_p5p6', 'u_td_p6p7', 'u_td_p7p8', 'u_td_p8p9', 'u_td_p9p10',\n",
    "    \"uac_prev1\", \"uac_prev2\",\n",
    "    \"elo_beta\", \"u_elo_theta\", \n",
    "    \"u_rate\",\n",
    "]\n",
    "nn_col = [f\"nn_svd{i}\" for i in range(20)]\n",
    "pred_col += nn_col\n",
    "print(pred_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col = [\n",
    "    \"pocket_1226\", \"sakami2\", \n",
    "    \"owruby2\", \n",
    "    \"lyaka2\",\n",
    "    #\"owruby2\", \"sakami\", \"pocket_1223\",\n",
    "    \"uc_td\", \"uc_ac_mean\", \n",
    "    \"ul_td\", \"u_td\", \"u_td_p1p2\", \n",
    "    \"ut_ac_mean\", \"ut_ac_mean2\",\n",
    "    \"up_ac_mean\",\n",
    "    \"et\", \"q_et_mean\", \"q_et_std\",\n",
    "    \"u_elo_theta\", \"q_ac_mean\", \n",
    "    \"up_ac_cnt\", \"uc_ac_cnt\", \"u_cnt\", \"q_ac_cnt\"\n",
    "]\n",
    "# pred_col += [\n",
    "#     \"et\",  \"q_ac_cnt\",  'b_ac_mean', 'b_ac_cnt', \"q_ac_mean\",\n",
    "#     \"u_ac_mean\", \"u_cnt\", \"u_qm_mean\", #\"u_td\", #\"uc_td\",\n",
    "#     \"u_ac_cnt\", #\"u_et_cnt\"\n",
    "#     'u_ok_qm_mean', 'u_ng_qm_mean',\n",
    "#     'q_et_mean', 'q_et_cnt', 'q_et_std',\n",
    "#    \"up_ac_cnt\", \"up_ac_mean\",\n",
    "#     \"u_td\", \n",
    "#     \"q_ng_uac_mean\",\"q_ok_uac_mean\", \"q_ok_uac_std\", \"q_ng_uac_std\",\n",
    "#     #\"correct_answer\",\n",
    "#     #\"u_ac_mean20\",\n",
    "#     \"ulr_ac_mean\", #\"ulr_ac_cnt\",  \"ub_cnt\",\n",
    "#     \"ut_ac_mean\",\"ut_ac_mean2\",\n",
    "#     \"uca_ac_mean\", \n",
    "#     \"ul_td\", \"u_td_wl\", \n",
    "#     #\"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\", \"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\",\n",
    "#     #\"pqhe\",\n",
    "#     \"uc_td\", \"uc_ac_mean\", \"uc_ac_cnt\", \n",
    "#     #\"u_td_final\", #\"ub_td_final\"\n",
    "#     'u_td_tp1','u_td_p1p2', 'u_td_p2p3', 'u_td_p3p4', 'u_td_p4p5',\n",
    "# #     'u_td_p5p6', 'u_td_p6p7', 'u_td_p7p8', 'u_td_p8p9', 'u_td_p9p10',\n",
    "#     #\"uac_prev1\", \"uac_prev2\",\n",
    "#     \"elo_beta\", \"u_elo_theta\", \n",
    "#     \"u_rate\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "fold= 0\n",
      "(3000000, 21) (2000000, 21)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.50492\n",
      "[200]\tvalid_0's binary_logloss: 0.4988\n",
      "[300]\tvalid_0's binary_logloss: 0.498361\n",
      "[400]\tvalid_0's binary_logloss: 0.498281\n",
      "[500]\tvalid_0's binary_logloss: 0.498253\n",
      "[600]\tvalid_0's binary_logloss: 0.498251\n",
      "Early stopping, best iteration is:\n",
      "[529]\tvalid_0's binary_logloss: 0.498249\n",
      "AUC= 0.8141540327254777\n",
      "           name  importance_split  importance_gain\n",
      "2       owruby2              5716         15425004\n",
      "1       sakami2              5593          6727567\n",
      "3        lyaka2              3684           744451\n",
      "0   pocket_1226              7122           479610\n",
      "4         uc_td              3323            72646\n",
      "6         ul_td              4188            64129\n",
      "5    uc_ac_mean              2018            57235\n",
      "16    q_ac_mean              3592            48886\n",
      "7          u_td              3445            47355\n",
      "19        u_cnt              3125            43795\n",
      "15  u_elo_theta              3376            40189\n",
      "8     u_td_p1p2              2797            34693\n",
      "11   up_ac_mean              2594            29851\n",
      "13    q_et_mean              2349            29285\n",
      "20     q_ac_cnt              2406            27664\n",
      "12           et              2277            27100\n",
      "9    ut_ac_mean              2132            26942\n",
      "10  ut_ac_mean2              2154            26628\n",
      "17    up_ac_cnt              2212            26228\n",
      "14     q_et_std              2203            25369\n",
      "18    uc_ac_cnt               348             5234\n"
     ]
    }
   ],
   "source": [
    "trainer = SingleTrainer(pred_col, dry_run=False)\n",
    "models, score = trainer.train_model(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f42a02ec310>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].save_model(\"./ensemble_model_0101.lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before lyaka 8140\n",
    "# after sakami1 8141\n",
    "# after lyaka12 8142\n",
    "# only lyaka12, no sakami1 0.81419: model0101\n",
    "# only lyaka2 0.81415\n",
    "\n",
    "# valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base feats\n",
    "#Early stopping, best iteration is:\n",
    "#[295]\tvalid_0's binary_logloss: 0.517508\n",
    "#AUC= 0.7967711921542647\n",
    "\n",
    "# with owruby, sakami\n",
    "# [73]\tvalid_0's binary_logloss: 0.499981\n",
    "#AUC= 0.812631130956799\n",
    "\n",
    "# add pocket1223\n",
    "#AUC= 0.8130389687940041\n",
    "\n",
    "#just 3\n",
    "#AUC= 0.8119216727001559\n",
    "\n",
    "# just3 + top feats\n",
    "#0.81279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeedLgb:\n",
    "    def __init__(self, seed=99, dry_run=False):\n",
    "        self.train_param = self.get_param(seed)\n",
    "        if dry_run:\n",
    "            self.num_rounds = 100\n",
    "        else:\n",
    "            self.num_rounds = 1100\n",
    "\n",
    "    def do_train_direct(self, x_train, y_train):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "\n",
    "        # print('Start training...')\n",
    "        model = lgb.train(self.train_param,\n",
    "                          lgb_train,\n",
    "                          valid_sets=None,\n",
    "                          verbose_eval=100,\n",
    "                          num_boost_round=self.num_rounds,\n",
    "                          #categorical_feature=[]\n",
    "                         )\n",
    "        # print('End training...')\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def show_feature_importance(model, filename=None):\n",
    "        fi = pd.DataFrame({\n",
    "            \"name\": model.feature_name(),\n",
    "            \"importance_split\": model.feature_importance(importance_type=\"split\").astype(int),\n",
    "            \"importance_gain\": model.feature_importance(importance_type=\"gain\").astype(int),\n",
    "        })\n",
    "        fi = fi.sort_values(by=\"importance_gain\", ascending=False)\n",
    "        #print(fi)\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            print(fi)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_param(seed):\n",
    "        return {\n",
    "            'num_leaves': 127,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'objective': 'binary',\n",
    "            #'metric': 'auc',\n",
    "            'metric': 'binary_logloss',\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.02,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"verbosity\": -1,\n",
    "            \"random_state\": seed,\n",
    "        }\n",
    "    \n",
    "class SeedTrainer:\n",
    "    def __init__(self, pred_col, dry_run=False):\n",
    "        self.pred_col = pred_col\n",
    "        self.target_col = \"ac\"\n",
    "        self.dry_run = dry_run\n",
    "\n",
    "    def train_model(self, df):\n",
    "        X = df[self.pred_col]\n",
    "        y = df[self.target_col]\n",
    "        \n",
    "        models, scores = list(), list()\n",
    "        for fold in range(4):\n",
    "            print(\"---------\")\n",
    "            print(\"fold=\", fold)\n",
    "            \n",
    "            lgbm = SeedLgb(seed=fold, dry_run=self.dry_run)\n",
    "            model = lgbm.do_train_direct(X, y)\n",
    "            #score = model.best_score[\"valid_0\"][\"binary_logloss\"]\n",
    "            #pred = model.predict(X_val)\n",
    "            #score = metrics.roc_auc_score(y_val, pred)\n",
    "            #print(\"AUC=\", score)\n",
    "            if fold == 0:\n",
    "                lgbm.show_feature_importance(model)\n",
    "            models.append(model)\n",
    "            #scores.append(score)\n",
    "        return models, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "fold= 0\n",
      "           name  importance_split  importance_gain\n",
      "1       sakami2              9218         21663621\n",
      "2       owruby2             10160         16689718\n",
      "0   pocket_1226             11127           640644\n",
      "3        lyaka2              7528           252855\n",
      "4         uc_td              6046           140199\n",
      "6         ul_td              9285           131655\n",
      "7          u_td              7975            96863\n",
      "5    uc_ac_mean              2511            93665\n",
      "19        u_cnt              7030            93439\n",
      "16    q_ac_mean              7188            89085\n",
      "15  u_elo_theta              7249            81063\n",
      "8     u_td_p1p2              6702            73352\n",
      "20     q_ac_cnt              6421            68977\n",
      "11   up_ac_mean              6620            68750\n",
      "13    q_et_mean              5564            64248\n",
      "17    up_ac_cnt              5850            62281\n",
      "9    ut_ac_mean              5259            61034\n",
      "12           et              5675            60832\n",
      "10  ut_ac_mean2              5133            57416\n",
      "14     q_et_std              5371            55588\n",
      "18    uc_ac_cnt               688            10562\n",
      "---------\n",
      "fold= 1\n",
      "---------\n",
      "fold= 2\n",
      "---------\n",
      "fold= 3\n"
     ]
    }
   ],
   "source": [
    "trainer = SeedTrainer(pred_col, dry_run=False)\n",
    "models, score = trainer.train_model(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    models[i].save_model(f\"./ensemble_model_0101_all{i}.lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115313781174149"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(merged2[\"label\"], merged2[\"ranked_3avg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 0.8115757793963951\n",
      "1.75 0.8115617807361065\n",
      "2 0.8115436387419797\n",
      "2.25 0.8115220983411143\n",
      "2.5 0.8114978412488558\n",
      "3 0.811442840131525\n",
      "3.5 0.8113818106061845\n",
      "4 0.8113171371978005\n"
     ]
    }
   ],
   "source": [
    "for power in [1.5, 1.75, 2, 2.25, 2.5, 3, 3.5, 4]:\n",
    "    merged2[\"power_mean\"] = (merged2[\"sakami\"]**power + merged2[\"owruby\"]**power + merged2[\"pocket_1223\"]**power)\n",
    "    score = metrics.roc_auc_score(merged2[\"label\"], merged2[\"power_mean\"])\n",
    "    print(power, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
