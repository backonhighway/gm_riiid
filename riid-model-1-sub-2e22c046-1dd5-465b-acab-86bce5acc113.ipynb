{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading riiid-test-answer-prediction, 1386476890 bytes zipped\n",
      "[==================================================] 1386476890 bytes downloaded\n",
      "Unzipping riiid-test-answer-prediction\n",
      "Failed to load https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/21651/1595136/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201201%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201201T040039Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=3caf7fe1d2c7614934bab0b5272e3a777f34cb6b89bf8bb7f1285d8eb39e7c949b03321adf9bd1841e75089e7bcafaf4283c0417c07e012bf9f3691bb5d5f8817ac3f7d2ce0896f12c82e274ce8af0ac0b3e789be7bf3c2d79b2850f5f23a29d3151ce503f69a6c1b8a8a5783e388216003dce9a980b9d4628b38583651563eda13004b57ac43a27bd179e0d448ac42da8ca30b477b880dec01c2a83f7d54b1f03ffdbb7805fc6e9bffbc18f723dc07a024755b661624698691c4bd1a52cfcf18d56ff62ec17949adac4e4ed9819f9759057989ca27c1bde63f67887c93d4c5e102549223f3b98ef67e8a407cc372c11b14e57e8452c903e8f25c5a5261611a4 to path /home/kaggle/input/riiid-test-answer-prediction\n",
      "Dataset import complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATASETS\n",
    "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
    "# THEN FEEL FREE TO DELETE CELL.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "\n",
    "CHUNK_SIZE = 40960 \n",
    "DATASET_MAPPING = 'riiid-test-answer-prediction:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F21651%2F1595136%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20201201%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20201201T040039Z%26X-Goog-Expires%3D259199%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3caf7fe1d2c7614934bab0b5272e3a777f34cb6b89bf8bb7f1285d8eb39e7c949b03321adf9bd1841e75089e7bcafaf4283c0417c07e012bf9f3691bb5d5f8817ac3f7d2ce0896f12c82e274ce8af0ac0b3e789be7bf3c2d79b2850f5f23a29d3151ce503f69a6c1b8a8a5783e388216003dce9a980b9d4628b38583651563eda13004b57ac43a27bd179e0d448ac42da8ca30b477b880dec01c2a83f7d54b1f03ffdbb7805fc6e9bffbc18f723dc07a024755b661624698691c4bd1a52cfcf18d56ff62ec17949adac4e4ed9819f9759057989ca27c1bde63f67887c93d4c5e102549223f3b98ef67e8a407cc372c11b14e57e8452c903e8f25c5a5261611a4'\n",
    "KAGGLE_INPUT_PATH='/home/kaggle/input'\n",
    "KAGGLE_INPUT_SYMLINK='/kaggle'\n",
    "\n",
    "#os.makedirs(KAGGLE_INPUT_PATH, 777)\n",
    "#os.symlink(KAGGLE_INPUT_PATH, os.path.join('..', 'input'), target_is_directory=True)\n",
    "#os.makedirs(KAGGLE_INPUT_SYMLINK)\n",
    "#os.symlink(KAGGLE_INPUT_PATH, os.path.join(KAGGLE_INPUT_SYMLINK, 'input'), target_is_directory=True)\n",
    "\n",
    "for dataset_mapping in DATASET_MAPPING.split(','):\n",
    "    directory, download_url_encoded = dataset_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as zipfileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = zipfileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes zipped')\n",
    "            dl = 0\n",
    "            data = zipfileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = zipfileres.read(CHUNK_SIZE)\n",
    "            print(f'\\nUnzipping {directory}')\n",
    "            with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "print('Dataset import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "#import riiideducation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "read_type = {\n",
    "    'row_id': 'int64',\n",
    "    'timestamp': 'int64',\n",
    "    'user_id': 'int32',\n",
    "    'content_id': 'int16',\n",
    "    'content_type_id': 'int8',\n",
    "    'task_container_id': 'int16',\n",
    "    'user_answer': 'int8',\n",
    "    'answered_correctly':'int8',\n",
    "    'prior_question_elapsed_time': 'float32',\n",
    "    'prior_question_had_explanation': 'boolean'\n",
    "}\n",
    "#train = pd.read_csv(\"/kaggle/input/riiid-test-answer-prediction/train.csv\", nrows=3*1000*1000, dtype=read_type)\n",
    "train = pd.read_csv(\"/home/pocket/input/train.csv\", dtype=read_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0       0          0      115        5692                0                  1   \n",
       "1       1      56943      115        5716                0                  2   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            3                   1                          NaN   \n",
       "1            2                   1                      37000.0   \n",
       "\n",
       "   prior_question_had_explanation  \n",
       "0                            <NA>  \n",
       "1                           False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_feather(\"./train.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./train.feather [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "\\ [1 files][  1.4 GiB/  1.4 GiB]   78.9 MiB/s                                   \n",
      "Operation completed over 1 objects/1.4 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./train.feather gs://dena-ai-training-24-gcp/riiid/train.feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: ../imported/ (stored 0%)\n",
      "  adding: ../imported/riid-model-1-sub-2e22c046-1dd5-465b-acab-86bce5acc113.ipynb (deflated 75%)\n",
      "  adding: ../imported/train.feather (deflated 74%)\n",
      "  adding: ../imported/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: ../imported/.ipynb_checkpoints/riid-model-1-sub-2e22c046-1dd5-465b-acab-86bce5acc113-checkpoint.ipynb (deflated 69%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r imported.zip ../imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./imported.zip [Content-Type=application/zip]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1 files][785.8 MiB/785.8 MiB]                                                \n",
      "Operation completed over 1 objects/785.8 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./imported.zip gs://dena-ai-training-24-gcp/riiid/imported.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51 131 162 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  bundle_id  correct_answer  part           tags\n",
       "0            0          0               0     1  51 131 162 38\n",
       "1            1          1               1     1      131 36 81"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = pd.read_csv(\"/home/pocket/input/questions.csv\")\n",
    "question.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "question[\"tags\"].astype(str).apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather(\"./train.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'user_answer', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "\n",
    "# no lectures for now\n",
    "train = train[train[\"answered_correctly\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tito-san cv\n",
    "import random\n",
    "random.seed(3)\n",
    "\n",
    "max_timestamp_u = train[['user_id','timestamp']].groupby(['user_id']).agg(['max']).reset_index()\n",
    "max_timestamp_u.columns = ['user_id', 'max_time_stamp']\n",
    "MAX_TIME_STAMP = max_timestamp_u.max_time_stamp.max()\n",
    "#(MAX_TIME_STAMP for all users) - (max_time_stamp for each user) is used for this interval.\n",
    "\n",
    "def rand_time(max_time_stamp):\n",
    "    interval = MAX_TIME_STAMP - max_time_stamp\n",
    "    rand_time_stamp = random.randint(0,interval)\n",
    "    return rand_time_stamp\n",
    "\n",
    "max_timestamp_u['rand_time_stamp'] = max_timestamp_u.max_time_stamp.apply(rand_time)\n",
    "train = train.merge(max_timestamp_u, on='user_id', how='left')\n",
    "train['virtual_time_stamp'] = train.timestamp + train['rand_time_stamp']\n",
    "\n",
    "# kaggle_env = True\n",
    "# if kaggle_env:\n",
    "#     # Full dataframe can not be sorted on kaggle kernel due to lack of memory.\n",
    "#     train = train[:1*1000*1000]\n",
    "train = train.sort_values(['virtual_time_stamp', 'row_id']).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_feather(\"./train_sorted_full.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cnt = Counter()\n",
    "u_ac_cnt = Counter()\n",
    "u_prev_ts = {}\n",
    "uc_prev_ts = {}\n",
    "u_prev_ac = {}\n",
    "uc_prev_ac = {}\n",
    "uc_prev2_ac = {}\n",
    "u_prev_ua = {}\n",
    "u_prev_qm = {}\n",
    "u_ac_sum, u_et_cnt, u_et_sum, u_qm_sum = Counter(), Counter(), Counter(), Counter()\n",
    "utc_ac_sum, utc_cnt = Counter(), Counter()\n",
    "utc_ts, u_prev_tc = {}, {}\n",
    "utc_prev_ts, utc_prev_ac, utc_prev_cnt = {}, {}, {}\n",
    "\n",
    "def init_values():\n",
    "    u_cnt.clear()\n",
    "    u_ac_cnt.clear()\n",
    "    u_prev_ts.clear()\n",
    "    uc_prev_ts.clear()\n",
    "    u_prev_ac.clear()\n",
    "    uc_prev_ac.clear()\n",
    "    uc_prev2_ac.clear()\n",
    "    u_prev_ua.clear()\n",
    "    u_prev_qm.clear()\n",
    "    u_ac_sum.clear()\n",
    "    u_et_cnt.clear()\n",
    "    u_et_sum.clear()\n",
    "    u_qm_sum.clear()\n",
    "    utc_ac_sum.clear()\n",
    "    utc_cnt.clear()\n",
    "    utc_ts.clear()\n",
    "    u_prev_tc.clear()\n",
    "    utc_prev_ts.clear()\n",
    "    utc_prev_ac.clear()\n",
    "    utc_prev_cnt.clear()\n",
    "\n",
    "def update_ac_values(prev_rows, prev_acs, prev_uas):\n",
    "    #for i, row in enumerate(prev_df.values):\n",
    "    for i, row in enumerate(prev_rows):\n",
    "        update_ac_value(row, prev_acs[i], prev_uas[i])\n",
    "    \n",
    "def update_ac_value(row, prev_ac, prev_ua):\n",
    "    uid = row[2]\n",
    "    cid = row[3]\n",
    "    ucid = (uid, cid)\n",
    "    \n",
    "    u_ac_cnt[uid] += 1\n",
    "    u_ac_sum[uid] += prev_ac\n",
    "    u_prev_ac[uid] = prev_ac\n",
    "    uc_prev_ac[ucid] = prev_ac\n",
    "    u_prev_ua[uid] = prev_ua\n",
    "\n",
    "def make_row(row, data_list, is_train=True):\n",
    "    ts = row[1]\n",
    "    uid = row[2]\n",
    "    cid = row[3]\n",
    "    tcid = row[5]\n",
    "    if is_train:\n",
    "        et = row[8]\n",
    "        pqhe = row[9]\n",
    "    else:\n",
    "        et = row[6]\n",
    "        pqhe = row[7]\n",
    "    ucid = (uid, cid)\n",
    "    utcid = (uid, tcid)\n",
    "    contents = contents_dict[cid]\n",
    "    \n",
    "    output = {}\n",
    "    if is_train:\n",
    "        output[\"ac\"] = row[7]\n",
    "    output[\"ts\"] = ts\n",
    "    output[\"uid\"] = uid\n",
    "    output[\"cid\"] = cid\n",
    "    output[\"tcid\"] = tcid\n",
    "    output[\"et\"] = et\n",
    "    output[\"pqhe\"] = pqhe\n",
    "    content_col = [\n",
    "        \"q_ac_mean\", \"q_ac_cnt\", \"q_et_mean\", \"q_et_cnt\", \"q_et_std\", \"b_ac_mean\", \"b_ac_cnt\",\n",
    "    ]\n",
    "    for c in content_col:\n",
    "        output[c] = contents[c]\n",
    "    \n",
    "    output[\"u_td\"] = u_prev_ts.get(uid, np.nan) - ts\n",
    "    output[\"uc_td\"] = uc_prev_ts.get(ucid, np.nan) - ts\n",
    "    u_prev_ts[uid] = ts\n",
    "    uc_prev_ts[ucid] = ts\n",
    "    \n",
    "    output[\"u_prev_ac\"] = u_prev_ac.get(uid, np.nan)\n",
    "    output[\"uc_prev_ac\"] = uc_prev_ac.get(ucid, np.nan)\n",
    "    output[\"u_prev_qm\"] = u_prev_qm.get(uid, np.nan)\n",
    "    output[\"u_prev_ua\"] = u_prev_ua.get(uid, np.nan)\n",
    "    u_prev_qm[uid] = contents[\"q_ac_mean\"]\n",
    "    \n",
    "    u_cnt[uid] += 1\n",
    "    u_qm_sum[uid] += contents[\"q_ac_mean\"]\n",
    "    output[\"u_cnt\"] = u_cnt[uid]\n",
    "    output[\"u_ac_cnt\"] = u_ac_cnt[uid]\n",
    "    output[\"u_ac_mean\"] = (u_ac_sum[uid] / u_ac_cnt[uid]) if u_ac_cnt[uid] != 0 else np.nan\n",
    "    output[\"u_qm_mean\"] = u_qm_sum[uid] / u_cnt[uid]\n",
    "    \n",
    "    if np.isnan(et):\n",
    "        output[\"u_et_mean\"] = np.nan\n",
    "    else:\n",
    "        u_et_cnt[uid] += 1\n",
    "        u_et_sum[uid] += et\n",
    "        output[\"u_et_mean\"] = u_et_sum[uid] / u_et_cnt[uid]\n",
    "    \n",
    "    data_list.append(output)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_train = train[:50*1000*1000].copy()\n",
    "train = train[50*1000*1000:]\n",
    "\n",
    "\n",
    "q_col = [\"question_id\", \"bundle_id\"]\n",
    "content_train = pd.merge(\n",
    "    content_train, question[q_col], left_on=\"content_id\", right_on=\"question_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# contents features\n",
    "# there are no new contents in the test, so we use part of the train as the pseudo-training set\n",
    "temp = content_train.groupby(\"content_id\")[\"answered_correctly\"].agg([\"mean\", \"count\"])\n",
    "temp.columns = [\"q_ac_mean\", \"q_ac_cnt\"]\n",
    "temp2 = content_train.groupby(\"content_id\")[\"prior_question_elapsed_time\"].agg([\"mean\", \"count\", \"std\"])\n",
    "temp2.columns = [\"q_et_mean\", \"q_et_cnt\", \"q_et_std\"]\n",
    "# temp3 = content_train.groupby(\"content_id\")[\"timestamp_diff\"].agg([\"mean\", \"std\", \"min\", \"max\", \"skew\"])\n",
    "# temp3.columns = [\"q_td_mean\", \"q_td_std\", \"q_td_min\", \"q_td_max\", \"q_td_skew\"]\n",
    "temp4 = content_train.groupby(\"bundle_id\")[\"answered_correctly\"].agg([\"mean\", \"count\"])\n",
    "temp4.columns = [\"b_ac_mean\", \"b_ac_cnt\"]\n",
    "q_col = [\"question_id\", \"bundle_id\"]\n",
    "#q_col += [str(i) for i in range(188)]\n",
    "contents = pd.merge(question[q_col], temp, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "contents = pd.merge(contents, temp2, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "#contents = pd.merge(contents, temp3, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "contents = pd.merge(contents, temp4, on=\"bundle_id\", how=\"left\")\n",
    "print(contents.head(2))\n",
    "print(contents.shape)\n",
    "merge_col = [\n",
    "    \"question_id\", \"q_ac_mean\", \"q_ac_cnt\", \"q_et_mean\",\n",
    "    \"q_et_cnt\", \"q_et_std\", \"b_ac_mean\", \"b_ac_cnt\"\n",
    "]\n",
    "contents = contents[merge_col]\n",
    "contents = contents.set_index(\"question_id\")\n",
    "contents_dict = contents.to_dict(\"index\")\n",
    "print(len(contents_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./contents_dict_50m_seed3.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(contents_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./contents_dict_50m_seed3.pkl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  1.1 MiB/  1.1 MiB]                                                \n",
      "Operation completed over 1 objects/1.1 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./contents_dict_50m_seed3.pkl gs://dena-ai-training-24-gcp/riiid/contents_dict.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLgb:\n",
    "    def __init__(self, seed=99, dry_run=False):\n",
    "        self.train_param = self.get_param()\n",
    "        if dry_run:\n",
    "            self.num_rounds = 100\n",
    "        else:\n",
    "            self.num_rounds = 1000\n",
    "\n",
    "    def do_train_direct(self, x_train, x_test, y_train, y_test):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "        # print('Start training...')\n",
    "        model = lgb.train(self.train_param,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_eval],\n",
    "                          verbose_eval=100,\n",
    "                          num_boost_round=self.num_rounds,\n",
    "                          early_stopping_rounds=100,\n",
    "                          #categorical_feature=[]\n",
    "                         )\n",
    "        # print('End training...')\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def show_feature_importance(model, filename=None):\n",
    "        fi = pd.DataFrame({\n",
    "            \"name\": model.feature_name(),\n",
    "            \"importance_split\": model.feature_importance(importance_type=\"split\").astype(int),\n",
    "            \"importance_gain\": model.feature_importance(importance_type=\"gain\").astype(int),\n",
    "        })\n",
    "        fi = fi.sort_values(by=\"importance_gain\", ascending=False)\n",
    "        print(fi)\n",
    "        #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            #print(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_param():\n",
    "        return {\n",
    "            'num_leaves': 31,\n",
    "            'min_data_in_leaf': 50,\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            #'metric': 'binary_logloss',\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.05,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"verbosity\": -1,\n",
    "            \"random_state\": 81,\n",
    "        }\n",
    "    \n",
    "class SingleTrainer:\n",
    "    def __init__(self, pred_col, dry_run=False):\n",
    "        self.pred_col = pred_col\n",
    "        self.target_col = \"ac\"\n",
    "        self.dry_run = dry_run\n",
    "        self.val_size = 200*1000\n",
    "\n",
    "    def train_model(self, df):\n",
    "        X = df[self.pred_col]\n",
    "        y = df[self.target_col]\n",
    "        \n",
    "        models, scores = list(), list()\n",
    "        for fold in range(4):\n",
    "            print(\"---------\")\n",
    "            print(\"fold=\", fold)\n",
    "            f, c = fold, self.val_size\n",
    "            val_s, val_e = -c-f*c, len(df)-f*c\n",
    "            train_idx = -c-f*c\n",
    "            X_train, X_val = X.iloc[:train_idx], X.iloc[val_s:val_e]\n",
    "            y_train, y_val = y.iloc[:train_idx], y.iloc[val_s:val_e]\n",
    "            print(X_train.shape, X_val.shape)\n",
    "            \n",
    "            lgbm = SingleLgb(seed=99, dry_run=self.dry_run)\n",
    "            model = lgbm.do_train_direct(X_train, X_val, y_train, y_val)\n",
    "            score = model.best_score[\"valid_0\"][\"auc\"]\n",
    "            pred = model.predict(X_val)\n",
    "            if fold == 0:\n",
    "                lgbm.show_feature_importance(model)\n",
    "            models.append(model)\n",
    "            scores.append(score)\n",
    "            break\n",
    "        return models, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49271300/49271300 [19:49<00:00, 41416.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ac           ts         uid   cid  tcid       et  pqhe  q_ac_mean  \\\n",
      "0   1  23758731186   392484238  5499  1995  20000.0  True   0.817723   \n",
      "1   1   1294359506  2041505565  8715   626  50000.0  True   0.669728   \n",
      "\n",
      "   q_ac_cnt     q_et_mean  ...  uc_td  u_prev_ac  uc_prev_ac  u_prev_qm  \\\n",
      "0    1388.0  25007.816406  ...    NaN        NaN         NaN        NaN   \n",
      "1    2831.0  25048.060547  ...    NaN        NaN         NaN        NaN   \n",
      "\n",
      "   u_prev_ua  u_cnt  u_ac_cnt  u_ac_mean  u_qm_mean  u_et_mean  \n",
      "0        NaN      1         0        NaN   0.817723    20000.0  \n",
      "1        NaN      1         0        NaN   0.669728    50000.0  \n",
      "\n",
      "[2 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data_list = list()\n",
    "utcid_set = set()\n",
    "prev_rows, prev_acs, prev_uas = list(), list(), list()\n",
    "init_values()\n",
    "\n",
    "not_updated_idx = 0\n",
    "for i, row in enumerate(tqdm(train.values)):\n",
    "    uid = row[2]\n",
    "    tcid = row[5]\n",
    "    utcid = (uid, tcid)\n",
    "    if utcid not in utcid_set:\n",
    "        if len(prev_rows) > 0:\n",
    "            #prev_df2 = train.iloc[not_updated_idx:i] iloc too slow lol\n",
    "            update_ac_values(prev_rows, prev_acs, prev_uas)\n",
    "            prev_rows.clear()\n",
    "            prev_acs.clear()\n",
    "            prev_uas.clear()\n",
    "            utcid_set.clear()\n",
    "            not_updated_idx = i\n",
    "    prev_rows.append(row)\n",
    "    prev_acs.append(row[7])\n",
    "    prev_uas.append(row[6])\n",
    "    utcid_set.add(utcid)\n",
    "    if i % 3*1000*1000 == 0:\n",
    "        init_values()\n",
    "        \n",
    "    make_row(row, train_data_list, True)\n",
    "        \n",
    "    \n",
    "df = pd.DataFrame(train_data_list)\n",
    "print(df.head(2))\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# df = pd.DataFrame(data_list)\n",
    "# 24.7 s ± 205 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ac</th>\n",
       "      <th>ts</th>\n",
       "      <th>uid</th>\n",
       "      <th>cid</th>\n",
       "      <th>tcid</th>\n",
       "      <th>et</th>\n",
       "      <th>q_ac_mean</th>\n",
       "      <th>q_ac_cnt</th>\n",
       "      <th>q_et_mean</th>\n",
       "      <th>q_et_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>uc_td</th>\n",
       "      <th>u_prev_ac</th>\n",
       "      <th>uc_prev_ac</th>\n",
       "      <th>u_prev_qm</th>\n",
       "      <th>u_prev_ua</th>\n",
       "      <th>u_cnt</th>\n",
       "      <th>u_ac_cnt</th>\n",
       "      <th>u_ac_mean</th>\n",
       "      <th>u_qm_mean</th>\n",
       "      <th>u_et_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.927130e+07</td>\n",
       "      <td>4.927130e+07</td>\n",
       "      <td>4.927130e+07</td>\n",
       "      <td>4.927130e+07</td>\n",
       "      <td>4.927130e+07</td>\n",
       "      <td>4.908798e+07</td>\n",
       "      <td>4.927129e+07</td>\n",
       "      <td>4.927129e+07</td>\n",
       "      <td>4.927129e+07</td>\n",
       "      <td>4.927129e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>3063.000000</td>\n",
       "      <td>17824.000000</td>\n",
       "      <td>3046.000000</td>\n",
       "      <td>7.725197e+06</td>\n",
       "      <td>17824.000000</td>\n",
       "      <td>4.927130e+07</td>\n",
       "      <td>4.927130e+07</td>\n",
       "      <td>17824.000000</td>\n",
       "      <td>4.927129e+07</td>\n",
       "      <td>4.908798e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.579535e-01</td>\n",
       "      <td>1.016223e+10</td>\n",
       "      <td>1.080510e+09</td>\n",
       "      <td>5.077734e+03</td>\n",
       "      <td>1.008177e+03</td>\n",
       "      <td>2.545773e+04</td>\n",
       "      <td>6.559170e-01</td>\n",
       "      <td>1.266337e+04</td>\n",
       "      <td>2.558852e+04</td>\n",
       "      <td>1.251167e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-1494.646425</td>\n",
       "      <td>0.464654</td>\n",
       "      <td>0.430401</td>\n",
       "      <td>6.665479e-01</td>\n",
       "      <td>1.374158</td>\n",
       "      <td>1.202909e+00</td>\n",
       "      <td>4.165508e-04</td>\n",
       "      <td>0.464399</td>\n",
       "      <td>6.559215e-01</td>\n",
       "      <td>2.545796e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.743951e-01</td>\n",
       "      <td>1.433762e+10</td>\n",
       "      <td>6.194332e+08</td>\n",
       "      <td>3.335634e+03</td>\n",
       "      <td>1.490978e+03</td>\n",
       "      <td>1.984836e+04</td>\n",
       "      <td>1.744216e-01</td>\n",
       "      <td>1.991321e+04</td>\n",
       "      <td>6.643313e+03</td>\n",
       "      <td>1.959918e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1965.331440</td>\n",
       "      <td>0.498763</td>\n",
       "      <td>0.495214</td>\n",
       "      <td>1.944112e-01</td>\n",
       "      <td>1.182778</td>\n",
       "      <td>5.039607e-01</td>\n",
       "      <td>2.437640e-02</td>\n",
       "      <td>0.489399</td>\n",
       "      <td>1.668116e-01</td>\n",
       "      <td>1.984784e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.150000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.192364e-02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.166667e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-33703.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.192364e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.192364e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.268123e+08</td>\n",
       "      <td>5.475871e+08</td>\n",
       "      <td>2.063000e+03</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>1.600000e+04</td>\n",
       "      <td>5.452756e-01</td>\n",
       "      <td>2.988000e+03</td>\n",
       "      <td>2.268620e+04</td>\n",
       "      <td>2.981000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-1956.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.466472e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.505618e-01</td>\n",
       "      <td>1.600000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.378293e+09</td>\n",
       "      <td>1.081135e+09</td>\n",
       "      <td>5.026000e+03</td>\n",
       "      <td>4.240000e+02</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>6.748187e-01</td>\n",
       "      <td>6.093000e+03</td>\n",
       "      <td>2.494064e+04</td>\n",
       "      <td>6.073000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-958.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.019600e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.738193e-01</td>\n",
       "      <td>2.100000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.433534e+10</td>\n",
       "      <td>1.616942e+09</td>\n",
       "      <td>7.427000e+03</td>\n",
       "      <td>1.228000e+03</td>\n",
       "      <td>2.966700e+04</td>\n",
       "      <td>7.868281e-01</td>\n",
       "      <td>1.232200e+04</td>\n",
       "      <td>2.590223e+04</td>\n",
       "      <td>1.230900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-379.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.220345e-01</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.793984e-01</td>\n",
       "      <td>2.966700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.742577e+10</td>\n",
       "      <td>2.147482e+09</td>\n",
       "      <td>1.352200e+04</td>\n",
       "      <td>9.999000e+03</td>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.141000e+05</td>\n",
       "      <td>6.451883e+04</td>\n",
       "      <td>1.140490e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ac            ts           uid           cid          tcid  \\\n",
       "count  4.927130e+07  4.927130e+07  4.927130e+07  4.927130e+07  4.927130e+07   \n",
       "mean   6.579535e-01  1.016223e+10  1.080510e+09  5.077734e+03  1.008177e+03   \n",
       "std    4.743951e-01  1.433762e+10  6.194332e+08  3.335634e+03  1.490978e+03   \n",
       "min    0.000000e+00  0.000000e+00  1.150000e+02  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  6.268123e+08  5.475871e+08  2.063000e+03  1.140000e+02   \n",
       "50%    1.000000e+00  3.378293e+09  1.081135e+09  5.026000e+03  4.240000e+02   \n",
       "75%    1.000000e+00  1.433534e+10  1.616942e+09  7.427000e+03  1.228000e+03   \n",
       "max    1.000000e+00  8.742577e+10  2.147482e+09  1.352200e+04  9.999000e+03   \n",
       "\n",
       "                 et     q_ac_mean      q_ac_cnt     q_et_mean      q_et_cnt  \\\n",
       "count  4.908798e+07  4.927129e+07  4.927129e+07  4.927129e+07  4.927129e+07   \n",
       "mean   2.545773e+04  6.559170e-01  1.266337e+04  2.558852e+04  1.251167e+04   \n",
       "std    1.984836e+04  1.744216e-01  1.991321e+04  6.643313e+03  1.959918e+04   \n",
       "min    0.000000e+00  9.192364e-02  3.000000e+00  1.166667e+04  3.000000e+00   \n",
       "25%    1.600000e+04  5.452756e-01  2.988000e+03  2.268620e+04  2.981000e+03   \n",
       "50%    2.100000e+04  6.748187e-01  6.093000e+03  2.494064e+04  6.073000e+03   \n",
       "75%    2.966700e+04  7.868281e-01  1.232200e+04  2.590223e+04  1.230900e+04   \n",
       "max    3.000000e+05  1.000000e+00  1.141000e+05  6.451883e+04  1.140490e+05   \n",
       "\n",
       "       ...         uc_td     u_prev_ac   uc_prev_ac     u_prev_qm  \\\n",
       "count  ...   3063.000000  17824.000000  3046.000000  7.725197e+06   \n",
       "mean   ...  -1494.646425      0.464654     0.430401  6.665479e-01   \n",
       "std    ...   1965.331440      0.498763     0.495214  1.944112e-01   \n",
       "min    ... -33703.000000      0.000000     0.000000  9.192364e-02   \n",
       "25%    ...  -1956.500000      0.000000     0.000000  5.466472e-01   \n",
       "50%    ...   -958.000000      0.000000     0.000000  7.019600e-01   \n",
       "75%    ...   -379.000000      1.000000     1.000000  8.220345e-01   \n",
       "max    ...      0.000000      1.000000     1.000000  1.000000e+00   \n",
       "\n",
       "          u_prev_ua         u_cnt      u_ac_cnt     u_ac_mean     u_qm_mean  \\\n",
       "count  17824.000000  4.927130e+07  4.927130e+07  17824.000000  4.927129e+07   \n",
       "mean       1.374158  1.202909e+00  4.165508e-04      0.464399  6.559215e-01   \n",
       "std        1.182778  5.039607e-01  2.437640e-02      0.489399  1.668116e-01   \n",
       "min        0.000000  1.000000e+00  0.000000e+00      0.000000  9.192364e-02   \n",
       "25%        0.000000  1.000000e+00  0.000000e+00      0.000000  5.505618e-01   \n",
       "50%        1.000000  1.000000e+00  0.000000e+00      0.000000  6.738193e-01   \n",
       "75%        3.000000  1.000000e+00  0.000000e+00      1.000000  7.793984e-01   \n",
       "max        3.000000  3.000000e+00  5.000000e+00      1.000000  1.000000e+00   \n",
       "\n",
       "          u_et_mean  \n",
       "count  4.908798e+07  \n",
       "mean   2.545796e+04  \n",
       "std    1.984784e+04  \n",
       "min    0.000000e+00  \n",
       "25%    1.600000e+04  \n",
       "50%    2.100000e+04  \n",
       "75%    2.966700e+04  \n",
       "max    3.000000e+05  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ac', 'ts', 'uid', 'cid', 'tcid', 'et', 'pqhe', 'q_ac_mean', 'q_ac_cnt',\n",
       "       'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean', 'b_ac_cnt', 'u_td',\n",
       "       'uc_td', 'u_prev_ac', 'uc_prev_ac', 'u_prev_qm', 'u_prev_ua', 'u_cnt',\n",
       "       'u_ac_cnt', 'u_ac_mean', 'u_qm_mean', 'u_et_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ts', 'q_ac_mean', 'q_ac_cnt', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean', 'b_ac_cnt', 'u_td', 'uc_td', 'u_prev_qm', 'u_cnt', 'u_qm_mean', 'u_et_mean', 'u_ac_mean', 'et']\n"
     ]
    }
   ],
   "source": [
    "pred_col = ['ts',  'q_ac_mean', 'q_ac_cnt',\n",
    "    'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean', 'b_ac_cnt', 'u_td',\n",
    "       'uc_td','u_prev_qm', 'u_cnt',\n",
    "       'u_qm_mean', 'u_et_mean', 'u_ac_mean', \n",
    "            \"et\", \n",
    "           # 'uid', 'cid', 'tcid', 'et',\n",
    "            #'pqhe', \n",
    "             #'u_prev_ac', 'uc_prev_ac', 'u_prev_ua', \n",
    "]\n",
    "print(pred_col)\n",
    "pred_col = [\n",
    "    \"ts\", \"et\", \"q_ac_mean\", \"q_ac_cnt\", 'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean', 'b_ac_cnt',\n",
    "    \"u_ac_mean\", \"u_cnt\", \"u_qm_mean\", \"u_td\", \"uc_td\",\n",
    "    #\"u_et_mean\", \"u_prev_qm\", \"u_ac_cnt\" small gain\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "fold= 0\n",
      "(49071300, 14) (200000, 14)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.728718\n",
      "[200]\tvalid_0's auc: 0.729631\n",
      "[300]\tvalid_0's auc: 0.730067\n",
      "[400]\tvalid_0's auc: 0.730271\n",
      "[500]\tvalid_0's auc: 0.730387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ea09454beb0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-9b545def283a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleLgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_train_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-9b545def283a>\u001b[0m in \u001b[0;36mdo_train_direct\u001b[0;34m(self, x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     17\u001b[0m                           \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                           \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                           \u001b[0;31m#categorical_feature=[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                          )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#temp_df = df[1*1000*1000:].copy()\n",
    "temp_df = df.copy()\n",
    "trainer = SingleTrainer(pred_col, dry_run=False)\n",
    "models, score = trainer.train_model(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard way\n",
    "#[1000]\tvalid_0's auc: 0.782993\n",
    "\n",
    "#periodic initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred_df(df):\n",
    "    pred_data_list = list()\n",
    "    for i, row in enumerate(df.values):\n",
    "        make_row(row, pred_data_list, False)\n",
    "    pred_df = pd.DataFrame(pred_data_list)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = riiideducation.make_env()\n",
    "is_train = False\n",
    "init_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_df = None\n",
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    #show_col = [\"row_id\", \"user_id\", \"content_type_id\", \"prior_group_answers_correct\", \"prior_group_responses\"]\n",
    "    #print(test_df.head(2))\n",
    "    #print(sample_prediction_df.head(2))\n",
    "    prev_ac = eval(test_df.iloc[0][\"prior_group_answers_correct\"])\n",
    "    prev_ua = eval(test_df.iloc[0][\"prior_group_responses\"])\n",
    "    use_df = test_df[test_df['content_type_id'] == 0]\n",
    "    #print(\"--------------------\")\n",
    "    \n",
    "    if len(prev_ac) > 0:\n",
    "        update_ac_values(prev_df.values, prev_ac, prev_ua)\n",
    "    pred_df = make_pred_df(use_df)\n",
    "    #print(pred_df.head(2))\n",
    "    pred = models[0].predict(pred_df[pred_col])\n",
    "    prev_df = use_df\n",
    "    \n",
    "    sub_df = use_df[[\"row_id\"]].copy()\n",
    "    sub_df[\"answered_correctly\"] = pred\n",
    "    env.predict(sub_df)\n",
    "    #test_df['answered_correctly'] = 0.5\n",
    "    #env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n",
    "\n",
    "\n",
    "#print(pred_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
