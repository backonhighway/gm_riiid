{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict, deque\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import feather\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from concurrent import futures\n",
    "#import riiideducation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51 131 162 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  bundle_id  correct_answer  part           tags\n",
       "0            0          0               0     1  51 131 162 38\n",
       "1            1          1               1     1      131 36 81"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = pd.read_csv(\"/home/pocket/input/questions.csv\")\n",
    "question.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>part</th>\n",
       "      <th>type_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lecture_id  tag  part  type_of\n",
       "0          89  159     5  concept\n",
       "1         100   70     1  concept"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecture = pd.read_csv(\"/home/pocket/input/lectures.csv\")\n",
    "lecture.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather(\"./train_sorted_full.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>max_time_stamp</th>\n",
       "      <th>rand_time_stamp</th>\n",
       "      <th>virtual_time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32933156</td>\n",
       "      <td>0</td>\n",
       "      <td>705741139</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>87425772049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32933157</td>\n",
       "      <td>20666</td>\n",
       "      <td>705741139</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>87425772049</td>\n",
       "      <td>0</td>\n",
       "      <td>20666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  timestamp    user_id  content_id  content_type_id  \\\n",
       "0  32933156          0  705741139         128                0   \n",
       "1  32933157      20666  705741139        7860                0   \n",
       "\n",
       "   task_container_id  user_answer  answered_correctly  \\\n",
       "0                  0            0                   1   \n",
       "1                  1            0                   1   \n",
       "\n",
       "   prior_question_elapsed_time  prior_question_had_explanation  \\\n",
       "0                          NaN                            <NA>   \n",
       "1                      16000.0                           False   \n",
       "\n",
       "   max_time_stamp  rand_time_stamp  virtual_time_stamp  \n",
       "0     87425772049                0                   0  \n",
       "1     87425772049                0               20666  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'user_answer', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation',\n",
      "       'max_time_stamp', 'rand_time_stamp', 'virtual_time_stamp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "\n",
    "# no lectures for now\n",
    "# train = train[train[\"answered_correctly\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"prior_question_had_explanation\"].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['concept', 'solving question', 'intention', 'starter'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecture[\"type_of\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture = lecture.set_index(\"lecture_id\")\n",
    "lectures_dict = lecture.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lectures_dict[89][\"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_pool():\n",
    "    u_cnt = Counter()\n",
    "    u_ac_cnt = Counter()\n",
    "    u_prev_ts = {}\n",
    "    uc_prev_ts = {}\n",
    "    ub_prev_ts = {}\n",
    "    u_ac_sum, u_qm_sum = Counter(), Counter()\n",
    "    u_ok_qm_sum, u_ng_qm_sum = Counter(), Counter()\n",
    "    u_ok_cnt, u_ng_cnt = Counter(), Counter()\n",
    "    uc_ac_sum, uc_ac_cnt = Counter(), Counter()\n",
    "    ub_ac_sum, ub_ac_cnt = Counter(), Counter()\n",
    "    ub_cnt = Counter()\n",
    "    ubb_cnt = Counter()\n",
    "    up_ac_cnt, up_ac_sum = Counter(), Counter()\n",
    "    ulr_ac_cnt, ulr_ac_sum = Counter(), Counter()\n",
    "    uca_ac_cnt, uca_ac_sum = Counter(), Counter()\n",
    "    prev_utd, prev_ubtd = {}, {}\n",
    "    u_ac_roll = defaultdict(lambda: deque(maxlen=20))\n",
    "    u_qm_roll = defaultdict(lambda: deque(maxlen=20))\n",
    "    uca_ac_sum, uca_ac_cnt = Counter(), Counter()\n",
    "    ut_ac_sum, ut_ac_cnt = Counter(), Counter()\n",
    "    \n",
    "    ul_prev_ts, u_prev_ts_wl, up_l_prev_ts, ut_l_prev_ts = {}, {}, {}, {}\n",
    "    prev_u_td_wl = {}\n",
    "    \n",
    "    data_pool = (u_cnt, u_ac_cnt, u_prev_ts, uc_prev_ts, u_ac_sum, u_qm_sum,\n",
    "                 u_ok_qm_sum, u_ng_qm_sum, u_ok_cnt, u_ng_cnt,\n",
    "                 ub_prev_ts, ub_cnt, ubb_cnt, up_ac_cnt, up_ac_sum, prev_utd, prev_ubtd,\n",
    "                 u_ac_roll, u_qm_roll, ulr_ac_cnt, ulr_ac_sum, uca_ac_sum, uca_ac_cnt,\n",
    "                 ut_ac_sum, ut_ac_cnt, ul_prev_ts, u_prev_ts_wl, up_l_prev_ts, ut_l_prev_ts,\n",
    "                 prev_u_td_wl, uc_ac_sum, uc_ac_cnt, ub_ac_sum, ub_ac_cnt\n",
    "                 \n",
    "                )\n",
    "    return data_pool\n",
    "\n",
    "def do_lecture(row, data_pool):\n",
    "    (u_cnt, u_ac_cnt, u_prev_ts, uc_prev_ts, u_ac_sum, u_qm_sum,\n",
    "     u_ok_qm_sum, u_ng_qm_sum, u_ok_cnt, u_ng_cnt, ub_prev_ts,\n",
    "     ub_cnt, ubb_cnt, up_ac_cnt, up_ac_sum, prev_utd, prev_ubtd,\n",
    "     u_ac_roll, u_qm_roll, ulr_ac_cnt, ulr_ac_sum, uca_ac_sum, uca_ac_cnt,\n",
    "     ut_ac_sum, ut_ac_cnt, ul_prev_ts, u_prev_ts_wl, up_l_prev_ts, ut_l_prev_ts,\n",
    "     prev_u_td_wl, uc_ac_sum, uc_ac_cnt, ub_ac_sum, ub_ac_cnt\n",
    "                ) = data_pool\n",
    "    ts = row[1]\n",
    "    uid = row[2]\n",
    "    cid = row[3]\n",
    "    lectures = lectures_dict[cid]\n",
    "    tag = lectures[\"tag\"]\n",
    "    part = lectures[\"part\"]\n",
    "    ltype = lectures[\"type_of\"]\n",
    "    type_dict = {'concept':0, 'solving question':1, 'intention':2, 'starter':3}\n",
    "    ltype = type_dict[ltype]\n",
    "    up = (uid, part)\n",
    "    ult = (uid, ltype)\n",
    "    ut = (uid, tag)\n",
    "    \n",
    "    ul_prev_ts[uid] = ts\n",
    "    u_prev_ts_wl[uid] = ts\n",
    "    up_l_prev_ts[up] = ts\n",
    "    ut_l_prev_ts[ut] = ts\n",
    "    \n",
    "    \n",
    "def update_ac_values(prev_rows, prev_acs, prev_uas, data_pool, is_train):\n",
    "    for i, row in enumerate(prev_rows):\n",
    "        update_ac_value(row, prev_acs[i], prev_uas[i], data_pool, is_train)\n",
    "    \n",
    "def update_ac_value(row, prev_ac, prev_ua, data_pool, is_train):\n",
    "    (u_cnt, u_ac_cnt, u_prev_ts, uc_prev_ts, u_ac_sum, u_qm_sum,\n",
    "     u_ok_qm_sum, u_ng_qm_sum, u_ok_cnt, u_ng_cnt, ub_prev_ts,\n",
    "     ub_cnt, ubb_cnt, up_ac_cnt, up_ac_sum, prev_utd, prev_ubtd,\n",
    "     u_ac_roll, u_qm_roll, ulr_ac_cnt, ulr_ac_sum, uca_ac_sum, uca_ac_cnt,\n",
    "     ut_ac_sum, ut_ac_cnt, ul_prev_ts, u_prev_ts_wl, up_l_prev_ts, ut_l_prev_ts,\n",
    "     prev_u_td_wl, uc_ac_sum, uc_ac_cnt, ub_ac_sum, ub_ac_cnt\n",
    "                ) = data_pool\n",
    "    uid = row[2]\n",
    "    cid = row[3]\n",
    "    contents = contents_dict[cid]\n",
    "    bid = contents[\"bundle_id\"]\n",
    "    qm = contents[\"q_ac_mean\"]\n",
    "    part = contents[\"part\"]\n",
    "    lr = part < 5\n",
    "    upid = (uid, part)\n",
    "    ulr = (uid, lr)\n",
    "    ca = contents[\"correct_answer\"]\n",
    "    ucid = (uid, cid)\n",
    "    ubid = (uid, bid)\n",
    "    uca = (uid, ca)\n",
    "    tags = contents[\"tags\"].split()\n",
    "    \n",
    "    u_ac_cnt[uid] += 1\n",
    "    u_ac_sum[uid] += prev_ac\n",
    "    uc_ac_cnt[ucid] += 1\n",
    "    uc_ac_sum[ucid] += prev_ac\n",
    "    ub_ac_cnt[ubid] += 1\n",
    "    ub_ac_sum[ubid] += prev_ac\n",
    "    up_ac_cnt[upid] += 1\n",
    "    up_ac_sum[upid] += prev_ac\n",
    "    ulr_ac_cnt[ulr] += 1\n",
    "    ulr_ac_sum[ulr] += prev_ac\n",
    "    u_ac_roll[uid].append(prev_ac)\n",
    "    uca_ac_cnt[uca] += 1\n",
    "    uca_ac_sum[uca] += prev_ac\n",
    "    \n",
    "    for tag in tags:\n",
    "        ut = (uid, tag)\n",
    "        ut_ac_sum[ut] += prev_ac\n",
    "        ut_ac_cnt[ut] += 1\n",
    "    \n",
    "    if prev_ac > 0.5:\n",
    "        u_ok_cnt[uid] += 1\n",
    "        u_ok_qm_sum[uid] += qm\n",
    "    else:\n",
    "        u_ng_cnt[uid] += 1\n",
    "        u_ng_qm_sum[uid] += qm\n",
    "\n",
    "def make_row(row, data_list, data_pool, is_train=True):\n",
    "    (u_cnt, u_ac_cnt, u_prev_ts, uc_prev_ts, u_ac_sum, u_qm_sum,\n",
    "     u_ok_qm_sum, u_ng_qm_sum, u_ok_cnt, u_ng_cnt, ub_prev_ts,\n",
    "     ub_cnt, ubb_cnt, up_ac_cnt, up_ac_sum, prev_utd, prev_ubtd,\n",
    "     u_ac_roll, u_qm_roll, ulr_ac_cnt, ulr_ac_sum, uca_ac_sum, uca_ac_cnt,\n",
    "     ut_ac_sum, ut_ac_cnt, ul_prev_ts, u_prev_ts_wl, up_l_prev_ts, ut_l_prev_ts,\n",
    "     prev_u_td_wl, uc_ac_sum, uc_ac_cnt, ub_ac_sum, ub_ac_cnt\n",
    "                ) = data_pool\n",
    "    ts = row[1]\n",
    "    uid = row[2]\n",
    "    cid = row[3]\n",
    "    tcid = row[5]\n",
    "    if is_train:\n",
    "        et = row[8]\n",
    "        pqhe = row[9]\n",
    "    else:\n",
    "        et = row[6]\n",
    "        pqhe = row[7]\n",
    "    ucid = (uid, cid)\n",
    "    utcid = (uid, tcid)\n",
    "    contents = contents_dict[cid]\n",
    "    bid = contents[\"bundle_id\"]\n",
    "    part = contents[\"part\"]\n",
    "    lr = part < 5\n",
    "    ubid = (uid, bid)\n",
    "    upid = (uid, part)\n",
    "    ulr = (uid, lr)\n",
    "    ca = contents[\"correct_answer\"]\n",
    "    uca = (uid, ca)\n",
    "    tags = contents[\"tags\"].split()\n",
    "    \n",
    "    output = {}\n",
    "    if is_train:\n",
    "        output[\"ac\"] = row[7]\n",
    "    output[\"ts\"] = ts\n",
    "    output[\"uid\"] = uid\n",
    "    output[\"cid\"] = cid\n",
    "    output[\"tcid\"] = tcid\n",
    "    output[\"et\"] = et\n",
    "    output[\"pqhe\"] = pqhe\n",
    "    output[\"bid\"] = bid\n",
    "    content_col = [\n",
    "        \"q_ac_mean\", \"q_ac_cnt\", \"q_et_mean\", \"q_et_cnt\", \"q_et_std\", \"b_ac_mean\", \"b_ac_cnt\",\n",
    "        \"part\", \"correct_answer\",\n",
    "        \"q_ok_uac_mean\", \"q_ok_uac_std\", \"q_ng_uac_mean\", \"q_ng_uac_std\",\n",
    "        \"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\", \"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\"\n",
    "    ]\n",
    "    for c in content_col:\n",
    "        output[c] = contents[c]\n",
    "        \n",
    "    utd = u_prev_ts.get(uid, np.nan) - ts\n",
    "    output[\"u_td\"] = utd\n",
    "    output[\"uc_td\"] = uc_prev_ts.get(ucid, np.nan) - ts\n",
    "    u_prev_ts[uid] = ts\n",
    "    uc_prev_ts[ucid] = ts\n",
    "    \n",
    "    ubtd = ub_prev_ts.get(ubid, np.nan) - ts\n",
    "    if ubtd < 0 or np.isnan(ubtd):\n",
    "        output[\"ub_td\"] = ubtd\n",
    "        output[\"ub_td2\"] = ubtd\n",
    "        ub_cnt[ubid] += 1\n",
    "        prev_ubtd[0] = ubtd\n",
    "    else:\n",
    "        output[\"ub_td2\"] = prev_ubtd[0]\n",
    "        \n",
    "    ub_prev_ts[ubid] = ts\n",
    "    output[\"ub_cnt\"] = ub_cnt[ubid]\n",
    "    \n",
    "    if utd < 0 or np.isnan(utd):\n",
    "        output[\"u_td2\"] = utd\n",
    "        prev_utd[0] = utd\n",
    "    else:\n",
    "        output[\"u_td2\"] = prev_utd[0]\n",
    "    \n",
    "    if ubtd == 0 or np.isnan(ubtd):\n",
    "        ubb_cnt[ubid] += 1\n",
    "    else:\n",
    "        ubb_cnt[ubid] = 0\n",
    "    output[\"ubb_cnt\"] = ubb_cnt[ubid]\n",
    "        \n",
    "    u_cnt[uid] += 1\n",
    "    u_qm_sum[uid] += contents[\"q_ac_mean\"]\n",
    "    u_qm_roll[uid].append(contents[\"q_ac_mean\"])\n",
    "    \n",
    "    output[\"u_cnt\"] = u_cnt[uid]\n",
    "    output[\"u_ac_cnt\"] = u_ac_cnt[uid]\n",
    "    output[\"u_ac_mean\"] = (u_ac_sum[uid] / u_ac_cnt[uid]) if u_ac_cnt[uid] != 0 else np.nan\n",
    "    output[\"ub_ac_cnt\"] = ub_ac_cnt[ubid]\n",
    "    output[\"ub_ac_mean\"] = (ub_ac_sum[ubid] /ub_ac_cnt[ubid]) if ub_ac_cnt[ubid] != 0 else np.nan\n",
    "    output[\"uc_ac_cnt\"] = uc_ac_cnt[ucid]\n",
    "    output[\"uc_ac_mean\"] = (uc_ac_sum[ucid] /uc_ac_cnt[ucid]) if uc_ac_cnt[ucid] != 0 else np.nan\n",
    "    output[\"uca_ac_cnt\"] = uca_ac_cnt[uca]\n",
    "    output[\"uca_ac_mean\"] = (uca_ac_sum[uca] / uca_ac_cnt[uca]) if uca_ac_cnt[uca] != 0 else np.nan\n",
    "    output[\"u_qm_mean\"] = u_qm_sum[uid] / u_cnt[uid]\n",
    "    output[\"u_qm_roll20\"] =  sum(u_qm_roll[uid]) / len(u_qm_roll[uid]) if len(u_qm_roll[uid]) != 0 else np.nan\n",
    "    \n",
    "    output[\"up_ac_cnt\"] = up_ac_cnt[upid]\n",
    "    output[\"up_ac_mean\"] = (up_ac_sum[upid] / up_ac_cnt[upid]) if up_ac_cnt[upid] != 0 else np.nan\n",
    "    output[\"ulr_ac_cnt\"] = ulr_ac_cnt[ulr]\n",
    "    output[\"ulr_ac_mean\"] = (ulr_ac_sum[ulr] / ulr_ac_cnt[ulr]) if ulr_ac_cnt[ulr] != 0 else np.nan\n",
    "    output[\"u_ok_qm_mean\"] = (u_ok_qm_sum[uid] / u_ok_cnt[uid]) if u_ok_cnt[uid] != 0 else np.nan\n",
    "    output[\"u_ng_qm_mean\"] = (u_ng_qm_sum[uid] / u_ng_cnt[uid]) if u_ng_cnt[uid] != 0 else np.nan\n",
    "    \n",
    "    output[\"u_ac_mean20\"] = sum(u_ac_roll[uid]) / len(u_ac_roll[uid]) if len(u_ac_roll[uid]) != 0 else np.nan\n",
    "    \n",
    "    ut_sum = 0\n",
    "    ut_cnt = 0\n",
    "    ut_mean = []\n",
    "    lt_cnt = 0\n",
    "    lt_td = []\n",
    "    for tag in tags:\n",
    "        ut = (uid, tag) \n",
    "        ut_sum += ut_ac_sum[ut]\n",
    "        ut_cnt += ut_ac_cnt[ut]\n",
    "        if ut_ac_cnt[ut] != 0:\n",
    "            ut_mean.append(ut_ac_sum[ut]/ut_ac_cnt[ut])\n",
    "            \n",
    "        utl_td = ut_l_prev_ts.get(ut, 0) - ts\n",
    "        if utl_td != 0:\n",
    "            lt_cnt += 1\n",
    "            lt_td.append(utl_td)\n",
    "    output[\"ut_ac_mean\"] = (ut_sum / ut_cnt) if ut_cnt != 0 else np.nan\n",
    "    output[\"ut_ac_mean2\"] = sum(ut_mean) / len(ut_mean) if len(ut_mean) != 0 else np.nan\n",
    "    output[\"u_lt_cnt\"] = lt_cnt\n",
    "    output[\"u_lt_mean\"] = sum(lt_td) / lt_cnt if lt_cnt != 0 else np.nan\n",
    "        \n",
    "    u_td_wl = u_prev_ts_wl.get(uid, np.nan) - ts\n",
    "    if u_td_wl < 0 or np.isnan(u_td_wl):\n",
    "        output[\"u_td_wl\"] = u_td_wl\n",
    "        prev_u_td_wl[0] = u_td_wl\n",
    "    else:\n",
    "        output[\"u_td_wl\"] = prev_u_td_wl[0]\n",
    "    \n",
    "    output[\"ul_td\"] = ul_prev_ts.get(uid, np.nan) - ts\n",
    "    output[\"upl_td\"] = up_l_prev_ts.get(upid, np.nan) - ts\n",
    "    \n",
    "    #ul_prev_ts[uid] = ts\n",
    "    u_prev_ts_wl[uid] = ts\n",
    "    \n",
    "    data_list.append(output)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_train = train[train[\"answered_correctly\"] != -1].copy()\n",
    "# content_train[\"temp_uac\"] = content_train.groupby(\"user_id\")[\"answered_correctly\"].transform(\"mean\")\n",
    "# # content_train[\"one\"] = 1\n",
    "# # content_train[\"temp_ucnt\"] = content_train.groupby(\"user_id\")[\"one\"].cumsum()\n",
    "# # content_train[\"temp_log_ucnt\"] = np.log1p(content_train[\"temp_ucnt\"])\n",
    "\n",
    "# q_col = [\"question_id\", \"bundle_id\"]\n",
    "# content_train = pd.merge(\n",
    "#     content_train, question[q_col], left_on=\"content_id\", right_on=\"question_id\", how=\"left\"\n",
    "# )\n",
    "\n",
    "# # contents features\n",
    "# # there are no new contents in the test, so we use part of the train as the pseudo-training set\n",
    "# temp = content_train.groupby(\"content_id\")[\"answered_correctly\"].agg([\"mean\", \"count\"])\n",
    "# temp.columns = [\"q_ac_mean\", \"q_ac_cnt\"]\n",
    "# temp2 = content_train.groupby(\"content_id\")[\"prior_question_elapsed_time\"].agg([\"mean\", \"count\", \"std\"])\n",
    "# temp2.columns = [\"q_et_mean\", \"q_et_cnt\", \"q_et_std\"]\n",
    "# # temp3 = content_train.groupby(\"content_id\")[\"timestamp_diff\"].agg([\"mean\", \"std\", \"min\", \"max\", \"skew\"])\n",
    "# # temp3.columns = [\"q_td_mean\", \"q_td_std\", \"q_td_min\", \"q_td_max\", \"q_td_skew\"]\n",
    "# temp4 = content_train.groupby(\"bundle_id\")[\"answered_correctly\"].agg([\"mean\", \"count\"])\n",
    "# temp4.columns = [\"b_ac_mean\", \"b_ac_cnt\"]\n",
    "\n",
    "# temp6 = content_train[content_train[\"answered_correctly\"]==1]\n",
    "# temp6 = temp6.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp6.columns = [\"q_ok_uac_mean\", \"q_ok_uac_std\"]\n",
    "\n",
    "# temp7 = content_train[content_train[\"answered_correctly\"]==0]\n",
    "# temp7 = temp7.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp7.columns = [\"q_ng_uac_mean\", \"q_ng_uac_std\"]\n",
    "\n",
    "# # temp8 = content_train.groupby(\"content_id\")[\"temp_ucnt\"].agg([\"mean\", \"std\", \"skew\"])\n",
    "# # temp8.columns = [\"q_ucnt_mean\", \"q_ucnt_std\", \"q_ucnt_skew\"]\n",
    "# # temp9 = content_train.groupby(\"content_id\")[\"temp_log_ucnt\"].agg([\"mean\", \"std\", \"skew\"])\n",
    "# # temp9.columns = [\"q_lucnt_mean\", \"q_lucnt_std\", \"q_lucnt_skew\"]\n",
    "# # temp10 = content_train[content_train[\"temp_ucnt\"]>10]\n",
    "# # temp10 = temp10.groupby(\"content_id\")[\"answered_correctly\"].agg([\"mean\"])\n",
    "# # temp10.columns = [\"q_ex10_mean\"]\n",
    "\n",
    "# temp11 = content_train[content_train[\"prior_question_had_explanation\"]==True]\n",
    "# temp11 = temp11.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp11.columns = [\"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\"]\n",
    "\n",
    "# temp12 = content_train[content_train[\"prior_question_had_explanation\"]==False]\n",
    "# temp12 = temp12.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp12.columns = [\"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\"]\n",
    "\n",
    "# question[\"b_cnt\"] = question.groupby(\"bundle_id\")[\"question_id\"].transform(\"count\")\n",
    "# q_col = [\"question_id\", \"bundle_id\", \"part\", \"correct_answer\", \"tags\", \"b_cnt\"]\n",
    "# #q_col += [str(i) for i in range(188)]\n",
    "# contents = pd.merge(question[q_col], temp, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp2, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# #contents = pd.merge(contents, temp3, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp4, on=\"bundle_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp6, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp7, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# # contents = pd.merge(contents, temp8, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# # contents = pd.merge(contents, temp9, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# # contents = pd.merge(contents, temp10, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp11, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp12, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# print(contents.head(2))\n",
    "# print(contents.shape)\n",
    "# merge_col = [\n",
    "#     \"question_id\", \"bundle_id\", \"part\", \"correct_answer\", \"tags\",\n",
    "#     \"q_ac_mean\", \"q_ac_cnt\", \"q_et_mean\",\n",
    "#     \"q_et_cnt\", \"q_et_std\", \"b_ac_mean\", \"b_ac_cnt\",\n",
    "#     \"q_ok_uac_mean\", \"q_ok_uac_std\", \"q_ng_uac_mean\", \"q_ng_uac_std\",\n",
    "#     \"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\", \"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\"\n",
    "#     #\"b_cnt\", \n",
    "# ]\n",
    "# contents = contents[merge_col]\n",
    "# contents[\"tags\"].fillna(\"-1\", inplace=True)\n",
    "# contents = contents.set_index(\"question_id\")\n",
    "# contents_dict = contents.to_dict(\"index\")\n",
    "# print(len(contents_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13523\n"
     ]
    }
   ],
   "source": [
    "# with open(\"./contents_dict_full_1208.pkl\", \"wb\") as handle:\n",
    "#     pickle.dump(contents_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# print(len(contents_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13523\n"
     ]
    }
   ],
   "source": [
    "with open(\"./contents_dict_full_1208.pkl\", \"rb\") as handle:\n",
    "    contents_dict = pickle.load(handle)\n",
    "print(len(contents_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_train = train[:50*1000*1000].copy()\n",
    "#train = train[50*1000*1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101230332\n"
     ]
    }
   ],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_train = pd.merge(train, contents, left_on=\"content_id\", right_on=\"question_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_train.groupby([\"part\", \"user_answer\"])[\"user_answer\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_train.groupby([\"part\", \"user_answer\"])[\"user_answer\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_col = [\"uid\", \"ts\", \"cid\", \"u_td\", \"u_td2\", \"ubb_cnt\", \"ub_cnt\", \"ub_td\", \"ac\"]\n",
    "# temp = df[df[\"uid\"]==891921072]\n",
    "\n",
    "# temp[temp[\"u_td\"]==0][show_col]\n",
    "# ##temp = df[df[\"ub_cnt\"]>1]\n",
    "# #temp[show_col].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[:100*1000].to_csv(\"./temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.iloc[:10*1000].to_csv(\"./temp_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLgb:\n",
    "    def __init__(self, seed=99, dry_run=False):\n",
    "        self.train_param = self.get_param()\n",
    "        if dry_run:\n",
    "            self.num_rounds = 100\n",
    "        else:\n",
    "            self.num_rounds = 500\n",
    "\n",
    "    def do_train_direct(self, x_train, x_test, y_train, y_test):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "        # print('Start training...')\n",
    "        model = lgb.train(self.train_param,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_eval],\n",
    "                          verbose_eval=100,\n",
    "                          num_boost_round=self.num_rounds,\n",
    "                          early_stopping_rounds=100,\n",
    "                          #categorical_feature=[]\n",
    "                         )\n",
    "        # print('End training...')\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def show_feature_importance(model, filename=None):\n",
    "        fi = pd.DataFrame({\n",
    "            \"name\": model.feature_name(),\n",
    "            \"importance_split\": model.feature_importance(importance_type=\"split\").astype(int),\n",
    "            \"importance_gain\": model.feature_importance(importance_type=\"gain\").astype(int),\n",
    "        })\n",
    "        fi = fi.sort_values(by=\"importance_gain\", ascending=False)\n",
    "        print(fi)\n",
    "        #with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            #print(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_param():\n",
    "        return {\n",
    "            'num_leaves': 127,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'objective': 'binary',\n",
    "            #'metric': 'auc',\n",
    "            'metric': 'binary_logloss',\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.1,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"verbosity\": -1,\n",
    "            \"random_state\": 81,\n",
    "        }\n",
    "    \n",
    "class SingleTrainer:\n",
    "    def __init__(self, pred_col, dry_run=False):\n",
    "        self.pred_col = pred_col\n",
    "        self.target_col = \"ac\"\n",
    "        self.dry_run = dry_run\n",
    "        self.val_size = 4*1000*1000\n",
    "\n",
    "    def train_model(self, df):\n",
    "        X = df[self.pred_col]\n",
    "        y = df[self.target_col]\n",
    "        \n",
    "        models, scores = list(), list()\n",
    "        for fold in range(4):\n",
    "            print(\"---------\")\n",
    "            print(\"fold=\", fold)\n",
    "            f, c = fold, self.val_size\n",
    "            val_s, val_e = -c-f*c, len(df)-f*c\n",
    "            train_idx = -c-f*c\n",
    "            X_train, X_val = X.iloc[:train_idx], X.iloc[val_s:val_e]\n",
    "            y_train, y_val = y.iloc[:train_idx], y.iloc[val_s:val_e]\n",
    "            print(X_train.shape, X_val.shape)\n",
    "            \n",
    "            lgbm = SingleLgb(seed=99, dry_run=self.dry_run)\n",
    "            model = lgbm.do_train_direct(X_train, X_val, y_train, y_val)\n",
    "            score = model.best_score[\"valid_0\"][\"binary_logloss\"]\n",
    "            pred = model.predict(X_val)\n",
    "            score = metrics.roc_auc_score(y_val, pred)\n",
    "            print(\"AUC=\", score)\n",
    "            if fold == 0:\n",
    "                lgbm.show_feature_importance(model)\n",
    "            models.append(model)\n",
    "            scores.append(score)\n",
    "            break\n",
    "        return models, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_list = list()\n",
    "# utcid_set = set()\n",
    "# prev_rows, prev_acs, prev_uas = list(), list(), list()\n",
    "# init_values()\n",
    "\n",
    "# not_updated_idx = 0\n",
    "# for i, row in enumerate(tqdm(train.values)):\n",
    "#     uid = row[2]\n",
    "#     tcid = row[5]\n",
    "#     utcid = (uid, tcid)\n",
    "#     if utcid not in utcid_set:\n",
    "#         if len(prev_rows) > 0:\n",
    "#             #prev_df2 = train.iloc[not_updated_idx:i] iloc too slow lol\n",
    "#             update_ac_values(prev_rows, prev_acs, prev_uas)\n",
    "#             prev_rows.clear()\n",
    "#             prev_acs.clear()\n",
    "#             prev_uas.clear()\n",
    "#             utcid_set.clear()\n",
    "#             not_updated_idx = i\n",
    "#     prev_rows.append(row)\n",
    "#     prev_acs.append(row[7])\n",
    "#     prev_uas.append(row[6])\n",
    "#     utcid_set.add(utcid)\n",
    "#     if i % 3*1000*1000 == 0:\n",
    "#         init_values()\n",
    "        \n",
    "#     make_row(row, train_data_list, True)\n",
    "        \n",
    "    \n",
    "# df = pd.DataFrame(train_data_list)\n",
    "# print(df.head(2))\n",
    "# #print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14553671\n",
      "(14268693, 57)\n",
      "93.87057328224182\n"
     ]
    }
   ],
   "source": [
    "def get_row(train_):\n",
    "    data_pool = make_data_pool()\n",
    "    train_data_list = list()\n",
    "    utcid_set = set()\n",
    "    prev_rows, prev_acs, prev_uas = list(), list(), list()\n",
    "\n",
    "    for i, row in enumerate(train_.values):\n",
    "        ctype = row[4]\n",
    "        if ctype == 1:\n",
    "            do_lecture(row, data_pool)\n",
    "            continue\n",
    "        uid = row[2]\n",
    "        tcid = row[5]\n",
    "        utcid = (uid, tcid)\n",
    "        if utcid not in utcid_set:\n",
    "            if len(prev_rows) > 0:\n",
    "                #prev_df2 = train.iloc[not_updated_idx:i] iloc too slow lol\n",
    "                update_ac_values(prev_rows, prev_acs, prev_uas, data_pool, True)\n",
    "                prev_rows.clear()\n",
    "                prev_acs.clear()\n",
    "                prev_uas.clear()\n",
    "                utcid_set.clear()\n",
    "                \n",
    "        prev_rows.append(row)\n",
    "        prev_acs.append(row[7])\n",
    "        prev_uas.append(row[6])\n",
    "        utcid_set.add(utcid)\n",
    "\n",
    "        make_row(row, train_data_list, data_pool, True)\n",
    "    \n",
    "    #return train_data_list\n",
    "\n",
    "\n",
    "    ret_df = pd.DataFrame(train_data_list)\n",
    "    return ret_df\n",
    "\n",
    "start_time = time.time()\n",
    "SPLIT_NUM = 16\n",
    "USE_FROM = 7\n",
    "\n",
    "train[\"uid_mod\"] = train[\"user_id\"] % (USE_FROM)\n",
    "train = train[train[\"uid_mod\"] == 0]\n",
    "print(len(train))\n",
    "\n",
    "train[\"uid_mod\"] = train[\"user_id\"] % (SPLIT_NUM)\n",
    "split_series = list()\n",
    "for i in range(0, SPLIT_NUM):\n",
    "    one_split = train[train[\"uid_mod\"] == i]\n",
    "    split_series.append(one_split)\n",
    "\n",
    "future_list = list()\n",
    "with futures.ProcessPoolExecutor(max_workers=SPLIT_NUM) as executor:\n",
    "    for s in split_series:\n",
    "        future_list.append(executor.submit(get_row, s))\n",
    "future_results = [f.result() for f in future_list]\n",
    "df = pd.concat(future_results)\n",
    "# future_results = []\n",
    "# for f in future_list:\n",
    "#     future_results += f.result()\n",
    "# df = pd.DataFrame(future_results)\n",
    "print(df.shape)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"b_done_ratio\"] = (df.groupby([\"uid\", \"tcid\"])[\"bid\"].transform(\"count\")) / (df[\"b_cnt\"])\n",
    "# df[\"ubb_cnt_rev\"] = df[\"bid\"] - df[\"ubb_cnt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# df = pd.DataFrame(data_list)\n",
    "# 24.7 s ± 205 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ac', 'ts', 'uid', 'cid', 'tcid', 'et', 'pqhe', 'bid', 'q_ac_mean',\n",
       "       'q_ac_cnt', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean',\n",
       "       'b_ac_cnt', 'part', 'correct_answer', 'q_ok_uac_mean', 'q_ok_uac_std',\n",
       "       'q_ng_uac_mean', 'q_ng_uac_std', 'q_pqhe_true_uac_mean',\n",
       "       'q_pqhe_true_uac_std', 'q_pqhe_false_uac_mean', 'q_pqhe_false_uac_std',\n",
       "       'u_td', 'uc_td', 'ub_td', 'ub_td2', 'ub_cnt', 'u_td2', 'ubb_cnt',\n",
       "       'u_cnt', 'u_ac_cnt', 'u_ac_mean', 'ub_ac_cnt', 'ub_ac_mean',\n",
       "       'uc_ac_cnt', 'uc_ac_mean', 'uca_ac_cnt', 'uca_ac_mean', 'u_qm_mean',\n",
       "       'u_qm_roll20', 'up_ac_cnt', 'up_ac_mean', 'ulr_ac_cnt', 'ulr_ac_mean',\n",
       "       'u_ok_qm_mean', 'u_ng_qm_mean', 'u_ac_mean20', 'ut_ac_mean',\n",
       "       'ut_ac_mean2', 'u_lt_cnt', 'u_lt_mean', 'u_td_wl', 'ul_td', 'upl_td'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['et', 'q_ac_mean', 'q_ac_cnt', 'b_ac_mean', 'b_ac_cnt', 'u_ac_mean', 'u_cnt', 'u_qm_mean', 'u_ac_cnt', 'u_ok_qm_mean', 'u_ng_qm_mean', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'ub_cnt', 'up_ac_cnt', 'up_ac_mean', 'u_td2', 'ub_td2', 'q_ng_uac_mean', 'q_ok_uac_mean', 'correct_answer', 'u_ac_mean20', 'ulr_ac_mean', 'ulr_ac_cnt', 'ut_ac_mean', 'uca_ac_mean', 'ut_ac_mean2', 'u_td_wl', 'ul_td', 'q_pqhe_true_uac_mean', 'q_pqhe_true_uac_std', 'q_pqhe_false_uac_mean', 'q_pqhe_false_uac_std', 'uc_td', 'uc_ac_mean', 'ub_ac_mean']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_col = [\n",
    "    \"et\", \"q_ac_mean\", \"q_ac_cnt\",  'b_ac_mean', 'b_ac_cnt',\n",
    "    \"u_ac_mean\", \"u_cnt\", \"u_qm_mean\", #\"u_td\", #\"uc_td\",\n",
    "    \"u_ac_cnt\", #\"u_et_cnt\"\n",
    "    #\"u_et_mean\", \"u_prev_qm\", small gain\n",
    "#     \"part\", \"ts\",\n",
    "    'u_ok_qm_mean', 'u_ng_qm_mean',\n",
    "    'q_et_mean', 'q_et_cnt', 'q_et_std',\n",
    "    #\"ub_td\",\n",
    "    # \"ubb_cnt\", \n",
    "    \"ub_cnt\",\"up_ac_cnt\", \"up_ac_mean\",\n",
    "    \"u_td2\", \"ub_td2\",\n",
    "    \"q_ng_uac_mean\",\"q_ok_uac_mean\", \n",
    "     #\"q_uac_mean\", \"q_uac_std\", \"q_ok_uac_std\",  \"q_ng_uac_mean\",\"q_ng_uac_std\",\n",
    "    #\"tcid\" #uca_ac_cnt\", \"uca_ac_mean\"\n",
    "    \"correct_answer\",\n",
    "    \"u_ac_mean20\",\n",
    "    #\"u_qm_roll20\"\n",
    "    #\"u_ac_10070\", \"u_ac_7050\", \"u_ac_500\", \"u_ac_700\"\n",
    "    #\"uid\", \"cid\"\n",
    "#     \"u_qm70_cnt\", \"u_qm50_cnt\", \"u_qm30_cnt\",\n",
    "#     \"u_qm70_ratio\", \"u_qm50_ratio\", \"u_qm30_ratio\"\n",
    "    \"ulr_ac_mean\", \"ulr_ac_cnt\",\n",
    "    #\"utd_mean\", \"b_cnt\", \"b_done_ratio\", \"uca_ac_cnt\", \"uca_ac_mean\",\n",
    "    #\"ubb_cnt_rev\", \"ut_ac_mean\", #\"ut_ac_mean2\"\n",
    "    \"ut_ac_mean\", \"uca_ac_mean\", \"ut_ac_mean2\",\n",
    "    \"u_td_wl\", \"ul_td\", \n",
    "    \"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\", \"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\",\n",
    "    #\"pqhe\",\n",
    "    \"uc_td\", \"uc_ac_mean\", #\"uc_ac_cnt\", \n",
    "    \"ub_ac_mean\", #\"ub_ac_cnt\"\n",
    "]\n",
    "new_col = [\n",
    "]\n",
    "pred_col += new_col\n",
    "print(pred_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# light_col = [\n",
    "#     'q_ac_mean', 'q_ac_cnt', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean', 'b_ac_cnt',\n",
    "#     'u_cnt', 'u_qm_mean', 'u_ac_mean', 'et', \"ub_td2\"\n",
    "# ]\n",
    "# new_light_col = [\n",
    "#     'u_ok_qm_mean', 'u_ng_qm_mean',\n",
    "#     \"up_ac_mean\", \"uca_ac_mean\",\n",
    "#     #\"ut_ac_mean\", \"ut_ac_mean2\", \"u_ac_mean20\", \n",
    "#     \"q_ng_uac_mean\",\"q_ok_uac_mean\", \n",
    "#     \"u_td2\", \n",
    "#     #\"ub_cnt\", \"ubb_cnt\",\n",
    "#     #\"up_ac_cnt\", \"u_ac_cnt\",\n",
    "#     \"correct_answer\", \"ulr_ac_mean\"\n",
    "# ]\n",
    "# pred_col = light_col + new_light_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a1ac8df37e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[1;32m   9972\u001b[0m         \"\"\"\n\u001b[1;32m   9973\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9974\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot describe a DataFrame without columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpercentiles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "df[new_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_col = [\n",
    "    'q_ac_mean', 'q_ac_cnt', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean', 'b_ac_cnt',\n",
    "    'u_cnt', 'u_qm_mean', 'u_ac_mean', 'et', \"ub_td2\", \"q_ng_uac_mean\",\"q_ok_uac_mean\", \n",
    "     \"correct_answer\", \"ulr_ac_mean\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "fold= 0\n",
      "(10268693, 37) (4000000, 37)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.51972\n",
      "[200]\tvalid_0's binary_logloss: 0.518164\n",
      "[300]\tvalid_0's binary_logloss: 0.517526\n",
      "[400]\tvalid_0's binary_logloss: 0.517181\n",
      "[500]\tvalid_0's binary_logloss: 0.516982\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's binary_logloss: 0.516982\n",
      "AUC= 0.7876575462107707\n",
      "                     name  importance_split  importance_gain\n",
      "1               q_ac_mean              2361          6791538\n",
      "5               u_ac_mean              2481          1069347\n",
      "34                  uc_td               986           782417\n",
      "3               b_ac_mean              1506           757843\n",
      "16             up_ac_mean              2085           650597\n",
      "10           u_ng_qm_mean              2978           624330\n",
      "23            ulr_ac_mean              1952           540071\n",
      "28                u_td_wl              2827           398026\n",
      "19          q_ng_uac_mean              3212           340684\n",
      "17                  u_td2              2673           255157\n",
      "18                 ub_td2              1690           215316\n",
      "20          q_ok_uac_mean              2753           205769\n",
      "22            u_ac_mean20               985           203457\n",
      "9            u_ok_qm_mean              2245           188234\n",
      "0                      et              1930           161833\n",
      "35             uc_ac_mean               510           123930\n",
      "29                  ul_td              2810           103122\n",
      "25             ut_ac_mean              1293            87741\n",
      "11              q_et_mean              1885            80275\n",
      "26            uca_ac_mean              1811            75283\n",
      "36             ub_ac_mean               644            70549\n",
      "24             ulr_ac_cnt              1743            63478\n",
      "13               q_et_std              1766            62971\n",
      "32  q_pqhe_false_uac_mean              1555            61229\n",
      "27            ut_ac_mean2              1267            60428\n",
      "6                   u_cnt              1541            60333\n",
      "15              up_ac_cnt              2007            55020\n",
      "30   q_pqhe_true_uac_mean              1643            50740\n",
      "31    q_pqhe_true_uac_std              2029            50319\n",
      "8                u_ac_cnt              1078            46082\n",
      "4                b_ac_cnt              1158            43237\n",
      "7               u_qm_mean              1415            42892\n",
      "33   q_pqhe_false_uac_std              1537            42709\n",
      "2                q_ac_cnt              1111            32488\n",
      "21         correct_answer               578            22795\n",
      "12               q_et_cnt               616            20031\n",
      "14                 ub_cnt               339            19671\n"
     ]
    }
   ],
   "source": [
    "#temp_df = df[1*1000*1000:].copy()\n",
    "temp_df = df.copy()\n",
    "trainer = SingleTrainer(pred_col, dry_run=False)\n",
    "models, score = trainer.train_model(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.7669-7670 starting\n",
    "#0.7672 with ng,okmean. \n",
    "#0.7664 without q_et_feats \n",
    "#uc_td=0.776...\n",
    "#ub_td=0.775\n",
    "#ubcnts=0.7764\n",
    "#up feats=0.7778\n",
    "#utd2=0.7785\n",
    "#ubtd2=0.7788\n",
    "#no utd, utdb=0.7789\n",
    "#contents_ac feats =0.7815\n",
    "#only mean of above =0.7812\n",
    "#utd_mean feats =0.7812\n",
    "#uca_ac_mean =0.7814\n",
    "#ca = 0.7815\n",
    "#tuned param to =0.7838\n",
    "#u_ac_mean20 =0.7842\n",
    "#u_ac_10070, 4 of them =0.7844\n",
    "#q_ucnts, qm_ex10 =0.7843\n",
    "#uid, cid=0.7839\n",
    "#u_qm_xx_ratio =0.7841\n",
    "#count common cids =0.7842\n",
    "#ac_mean common cids =0.7842\n",
    "#ng_mean common cids =0.7842\n",
    "#qmroll20 =0.7841\n",
    "#ulr =0.7842\n",
    "#lots of shit =0.7855\n",
    "#utag =0.7847\n",
    "#uca =0.7850\n",
    "#utag+uca =0.7854\n",
    "\n",
    "# for sub, light_cols =0.7850\n",
    "\n",
    "#lectures =0.7860\n",
    "#drop lecture_cnts =0.7861\n",
    "#pqhe feats=0.7864\n",
    "#other uc, ub feats=0.7876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
