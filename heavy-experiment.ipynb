{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict, deque\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import skew\n",
    "\n",
    "import feather\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from concurrent import futures\n",
    "#import riiideducation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51 131 162 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  bundle_id  correct_answer  part           tags\n",
       "0            0          0               0     1  51 131 162 38\n",
       "1            1          1               1     1      131 36 81"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = pd.read_csv(\"/home/pocket/input/questions.csv\")\n",
    "question.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "question[\"tags\"].astype(str).apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>part</th>\n",
       "      <th>type_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>159</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lecture_id  tag  part  type_of\n",
       "0          89  159     5  concept\n",
       "1         100   70     1  concept"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecture = pd.read_csv(\"/home/pocket/input/lectures.csv\")\n",
    "lecture.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture = lecture.set_index(\"lecture_id\")\n",
    "lectures_dict = lecture.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_feather(\"./train_sorted_full2.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[\"prior_question_had_explanation\"].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[\"prior_question_had_explanation\"] = train[\"prior_question_had_explanation\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_col = [\n",
    "#     'row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
    "#     'task_container_id', 'user_answer', 'answered_correctly',\n",
    "#     'prior_question_elapsed_time', 'prior_question_had_explanation',\n",
    "# ]\n",
    "# train[use_col].to_feather(\"./train_sorted_full2.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'user_answer', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "\n",
    "# no lectures for now\n",
    "#train = train[train[\"answered_correctly\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32933156</td>\n",
       "      <td>0</td>\n",
       "      <td>705741139</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32933157</td>\n",
       "      <td>20666</td>\n",
       "      <td>705741139</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  timestamp    user_id  content_id  content_type_id  \\\n",
       "0  32933156          0  705741139         128                0   \n",
       "1  32933157      20666  705741139        7860                0   \n",
       "\n",
       "   task_container_id  user_answer  answered_correctly  \\\n",
       "0                  0            0                   1   \n",
       "1                  1            0                   1   \n",
       "\n",
       "   prior_question_elapsed_time  prior_question_had_explanation  \n",
       "0                          NaN                               0  \n",
       "1                      16000.0                               0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PocketCounter():\n",
    "    def __init__(self):\n",
    "        self.cnt = Counter()\n",
    "        self.sum = Counter()\n",
    "    \n",
    "    def update(self, key, sum_val):\n",
    "        self.cnt[key] += 1\n",
    "        self.sum[key] += sum_val\n",
    "        \n",
    "    def get_mean(self, key):\n",
    "        return (self.sum[key] / self.cnt[key]) if self.cnt[key] != 0 else np.nan\n",
    "\n",
    "class PocketRoller():\n",
    "    def __init__(self, roll50=False):\n",
    "        self.roll = defaultdict(self.get_deq20)\n",
    "            \n",
    "    def update(self, key, val):\n",
    "        self.roll[key].append(val)\n",
    "        \n",
    "    def get_deq20(self):\n",
    "        return deque(maxlen=20)\n",
    "    \n",
    "    def get_mean(self, key):\n",
    "        return sum(self.roll[key]) / len(self.roll[key]) if len(self.roll[key]) != 0 else np.nan\n",
    "    \n",
    "\n",
    "class PocketTimestamp():\n",
    "    def __init__(self):\n",
    "        self.prev_ts = {}\n",
    "        self.prev_td = 0\n",
    "        self.td = 0\n",
    "    \n",
    "    def update(self, key, ts):\n",
    "        td = self.prev_ts.get(key, np.nan) - ts\n",
    "        if td < 0 or np.isnan(td):\n",
    "            self.td = td\n",
    "            self.prev_td = td\n",
    "        else:\n",
    "            self.td = self.prev_td\n",
    "        self.prev_ts[key] = ts\n",
    "        \n",
    "    def update_only_ts(self, key, ts):\n",
    "        self.prev_ts[key] = ts\n",
    "        \n",
    "    def get_simple_td(self, key, ts):\n",
    "        return self.prev_ts.get(key, np.nan) - ts\n",
    "\n",
    "    \n",
    "class PocketTSRoller():\n",
    "    def __init__(self):\n",
    "        self.roll = defaultdict(self.get_deq)\n",
    "    \n",
    "    def update(self, key, val):\n",
    "        if len(self.roll[key]) == 0:\n",
    "            self.roll[key].append(val)\n",
    "        \n",
    "        if val - self.roll[key][-1] != 0:\n",
    "            self.roll[key].append(val)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def get_prev_t(self, key, t):\n",
    "        if len(self.roll[key]) < t:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return self.roll[key][-t]\n",
    "        \n",
    "    def get_deq(self):\n",
    "        return deque(maxlen=10)\n",
    "            \n",
    "    \n",
    "class PocketElo():\n",
    "    def __init__(self):\n",
    "        self.u_theta = {}\n",
    "        self.u_cnt = {}\n",
    "        self.left_asymptote = 0.25\n",
    "        \n",
    "    def get_theta(self, uid):\n",
    "        if uid not in self.u_theta.keys():\n",
    "            return np.nan\n",
    "        else:\n",
    "            return self.u_theta[uid]\n",
    "        \n",
    "    def init_user(self, uid):\n",
    "        if uid not in self.u_theta.keys():\n",
    "            self.u_theta[uid] = 0\n",
    "            self.u_cnt[uid] = 0\n",
    "    \n",
    "    def update(self, uid, ac, beta):\n",
    "        self.init_user(uid)\n",
    "        \n",
    "        theta, cnt = self.u_theta[uid], self.u_cnt[uid]\n",
    "        self.u_theta[uid] = self.get_new_theta(ac, beta, theta, cnt)\n",
    "        self.u_cnt[uid] += 1\n",
    "    \n",
    "    def get_new_theta(self, ac, beta, theta, cnt):\n",
    "        return theta + self.learning_rate_theta(cnt) * (ac - self.ac_prob(theta, beta))\n",
    "    \n",
    "    def learning_rate_theta(self, cnt):\n",
    "        return max(0.3 / (1 + 0.01 * cnt), 0.04)\n",
    "    \n",
    "    def ac_prob(self, theta, beta):\n",
    "        return self.left_asymptote + (1 - self.left_asymptote) * self.sigmoid(theta - beta)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PocketFeatureFactory():\n",
    "    def __init__(self, is_train, contents_dict):\n",
    "        self.u_ac = PocketCounter()\n",
    "        self.uc_ac = PocketCounter()\n",
    "        self.u_qm = PocketCounter()\n",
    "        self.u_ac_roll = PocketRoller()\n",
    "        self.u_ts = PocketTimestamp()\n",
    "        self.uc_ts = PocketTimestamp()\n",
    "        self.u_ok_qm = PocketCounter()\n",
    "        self.u_ng_qm = PocketCounter()\n",
    "        self.up_ac = PocketCounter()\n",
    "        self.ulr_ac = PocketCounter()\n",
    "        self.uca_ac = PocketCounter()\n",
    "        self.ut_ac = PocketCounter()\n",
    "        self.ul_ts = PocketTimestamp()\n",
    "        self.u_ts_wl = PocketTimestamp()\n",
    "        self.u_ts_roll = PocketTSRoller()\n",
    "        self.u_elo = PocketElo()\n",
    "        self.u_rate = PocketCounter()\n",
    "        \n",
    "        self.u_ng_ts = PocketTimestamp()\n",
    "        \n",
    "        self.u_first_b = {}\n",
    "        \n",
    "        self.contents_dict = contents_dict\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def get_row_tuple(self, row):\n",
    "        ts, uid, cid, tcid = row[1], row[2], row[3], row[5]\n",
    "        if self.is_train:\n",
    "            et = row[8]\n",
    "            pqhe = row[9]\n",
    "        else:\n",
    "            et = row[6]\n",
    "            pqhe = row[7]\n",
    "            \n",
    "        return (ts, uid, cid, tcid, et, pqhe)\n",
    "        \n",
    "    def unpack_row(self, row):\n",
    "        (ts, uid, cid, tcid, et, pqhe) = self.get_row_tuple(row)\n",
    "        \n",
    "        contents = self.contents_dict[cid]\n",
    "        qm = contents[\"q_ac_mean\"]\n",
    "        bid = contents[\"bundle_id\"]\n",
    "        part = contents[\"part\"]\n",
    "        ca = contents[\"correct_answer\"]\n",
    "        lr = part < 5\n",
    "        tags = contents[\"tags\"].split()\n",
    "        \n",
    "        ucid = (uid, cid)\n",
    "        utcid = (uid, tcid)\n",
    "        ubid = (uid, bid)\n",
    "        upid = (uid, part)\n",
    "        ulr = (uid, lr)\n",
    "        uca = (uid, ca)\n",
    "        return (ts, uid, cid, tcid, et, pqhe, qm, tags, ucid, utcid, ubid, upid, ulr, uca)\n",
    "    \n",
    "    def do_lecture(self, row):\n",
    "        ts, uid, cid = row[1], row[2], row[3]\n",
    "        self.ul_ts.update_only_ts(uid, ts)\n",
    "        self.u_ts_wl.update_only_ts(uid, ts)\n",
    "        self.u_ts_roll.update(uid, ts)\n",
    "    \n",
    "    def update_ac_values(self, prev_rows, prev_acs, prev_uas):\n",
    "        for i, row in enumerate(prev_rows):\n",
    "            self.update_ac_value(row, prev_acs[i], prev_uas[i])\n",
    "    \n",
    "    def update_ac_value(self, row, prev_ac, prev_ua):\n",
    "        ts, uid, cid, tcid, et, pqhe, qm, tags, ucid, utcid, ubid, upid, ulr, uca = self.unpack_row(row)\n",
    "        contents = self.contents_dict[cid]\n",
    "        \n",
    "        self.u_ac.update(uid, prev_ac)\n",
    "        self.uc_ac.update(ucid, prev_ac)\n",
    "        self.up_ac.update(upid, prev_ac)\n",
    "        self.ulr_ac.update(ulr, prev_ac)\n",
    "        self.uca_ac.update(uca, prev_ac)\n",
    "        self.u_ac_roll.update(uid, prev_ac)\n",
    "\n",
    "        for tag in tags:\n",
    "            ut = (uid, tag)\n",
    "            self.ut_ac.update(ut, prev_ac)\n",
    "\n",
    "        if prev_ac > 0.5:\n",
    "            self.u_ok_qm.update(uid, qm)\n",
    "            self.u_rate.update(uid, contents[\"q_ok_uac_mean\"])\n",
    "        else:\n",
    "            self.u_ng_qm.update(uid, qm)\n",
    "            self.u_rate.update(uid, contents[\"q_ng_uac_mean\"])\n",
    "            self.u_ng_ts.update_only_ts(uid, ts)\n",
    "        \n",
    "        beta = contents[\"elo_beta\"]\n",
    "        self.u_elo.update(uid, prev_ac, beta)\n",
    "\n",
    "    def make_row(self, row, data_list):\n",
    "        ts, uid, cid, tcid, et, pqhe, qm, tags, ucid, utcid, ubid, upid, ulr, uca = self.unpack_row(row)\n",
    "\n",
    "        output = {}\n",
    "        if self.is_train:\n",
    "            output[\"ac\"] = row[7]\n",
    "        output[\"et\"] = et\n",
    "        \n",
    "        contents = self.contents_dict[cid]\n",
    "        content_col = [\n",
    "            \"q_ac_mean\", \"q_ac_cnt\", \"q_et_mean\", \"q_et_cnt\", \"q_et_std\", \"b_ac_mean\", \"b_ac_cnt\",\n",
    "            \"part\", \"correct_answer\",\n",
    "            \"q_ok_uac_mean\", \"q_ok_uac_std\", \"q_ng_uac_mean\", \"q_ng_uac_std\",\n",
    "            \"elo_beta\",\n",
    "            \"pqhe_mean\"\n",
    "        ]\n",
    "        nn_col = [f\"nn_svd{i}\" for i in range(20)]\n",
    "        content_col += nn_col\n",
    "        \n",
    "        for c in content_col:\n",
    "            output[c] = contents[c]\n",
    "            \n",
    "        self.u_ts.update(uid, ts)\n",
    "        self.uc_ts.update(ucid, ts)\n",
    "        self.u_ts_wl.update(uid, ts)\n",
    "        output[\"u_td\"] = self.u_ts.td\n",
    "        output[\"uc_td\"] = self.uc_ts.td\n",
    "        output[\"u_td_wl\"] = self.u_ts_wl.td\n",
    "        output[\"ul_td\"] = self.ul_ts.get_simple_td(uid, ts)\n",
    "\n",
    "        self.u_qm.update(uid, qm)\n",
    "        output[\"u_cnt\"] = self.u_qm.cnt[uid]\n",
    "        output[\"u_ac_cnt\"] = self.u_ac.cnt[uid]\n",
    "        output[\"u_ac_mean\"] = self.u_ac.get_mean(uid)\n",
    "        output[\"uc_ac_cnt\"] = self.uc_ac.cnt[ucid]\n",
    "        output[\"uc_ac_mean\"] = self.uc_ac.get_mean(ucid)\n",
    "        output[\"uca_ac_mean\"] = self.uca_ac.get_mean(uca)\n",
    "        output[\"u_qm_mean\"] = self.u_qm.get_mean(uid)\n",
    "        output[\"up_ac_cnt\"] = self.up_ac.cnt[upid]\n",
    "        output[\"up_ac_mean\"] = self.up_ac.get_mean(upid)\n",
    "        output[\"ulr_ac_mean\"] = self.ulr_ac.get_mean(ulr)\n",
    "        output[\"u_ok_qm_mean\"] = self.u_ok_qm.get_mean(uid)\n",
    "        output[\"u_ng_qm_mean\"] = self.u_ng_qm.get_mean(uid)\n",
    "        output[\"u_ac_mean20\"] = self.u_ac_roll.get_mean(uid)\n",
    "        \n",
    "        output[\"u_rate\"] = self.u_rate.get_mean(uid)\n",
    "        \n",
    "        output[\"u_elo_theta\"] = self.u_elo.get_theta(uid)\n",
    "        \n",
    "        if len(self.u_ac_roll.roll[uid]) < 1:\n",
    "            output[\"uac_prev1\"] = np.nan\n",
    "        else:\n",
    "            output[\"uac_prev1\"]= self.u_ac_roll.roll[uid][-1]\n",
    "        if len(self.u_ac_roll.roll[uid]) < 2:\n",
    "            output[\"uac_prev2\"] = np.nan\n",
    "        else:\n",
    "            output[\"uac_prev2\"]= self.u_ac_roll.roll[uid][-2]\n",
    "        \n",
    "        up1 = self.u_ts_roll.get_prev_t(uid, 1)\n",
    "        up2 = self.u_ts_roll.get_prev_t(uid, 2)\n",
    "        up3 = self.u_ts_roll.get_prev_t(uid, 3)\n",
    "        up4 = self.u_ts_roll.get_prev_t(uid, 4)\n",
    "        up5 = self.u_ts_roll.get_prev_t(uid, 5)\n",
    "        up6 = self.u_ts_roll.get_prev_t(uid, 6)\n",
    "        up7 = self.u_ts_roll.get_prev_t(uid, 7)\n",
    "        up8 = self.u_ts_roll.get_prev_t(uid, 8)\n",
    "        up9 = self.u_ts_roll.get_prev_t(uid, 9)\n",
    "        up10 = self.u_ts_roll.get_prev_t(uid, 10)\n",
    "        output[\"u_td_tp1\"] = ts - up1\n",
    "        output[\"u_td_p1p2\"] = up1 - up2\n",
    "        output[\"u_td_p2p3\"] = up2 - up3\n",
    "        output[\"u_td_p3p4\"] = up3 - up4\n",
    "        output[\"u_td_p4p5\"] = up4 - up5\n",
    "        output[\"u_td_p5p6\"] = up5 - up6\n",
    "        output[\"u_td_p6p7\"] = up6 - up7\n",
    "        output[\"u_td_p7p8\"] = up7 - up8\n",
    "        output[\"u_td_p8p9\"] = up8 - up9\n",
    "        output[\"u_td_p9p10\"] = up9 - up10\n",
    "        self.u_ts_roll.update(uid, ts)\n",
    "        \n",
    "        #temp_b_cnt = row[11]\n",
    "        #output[\"u_td_final\"] = output[\"u_td_wl\"] / temp_b_cnt\n",
    "        #output[\"ub_td_final\"] = output[\"ub_td\"] / temp_b_cnt\n",
    "        \n",
    "        ut_sum = 0\n",
    "        ut_cnt = 0\n",
    "        ut_mean = []\n",
    "        for tag in tags:\n",
    "            ut = (uid, tag)\n",
    "            ut_sum += self.ut_ac.sum[ut]\n",
    "            ut_cnt += self.ut_ac.cnt[ut]\n",
    "            if self.ut_ac.cnt[ut] != 0:\n",
    "                ut_mean.append(self.ut_ac.get_mean(ut))\n",
    "        output[\"ut_ac_mean\"] = (ut_sum / ut_cnt) if ut_cnt != 0 else np.nan\n",
    "        output[\"ut_ac_mean2\"] = sum(ut_mean) / len(ut_mean) if len(ut_mean) != 0 else np.nan\n",
    "        \n",
    "        output[\"u_ng_ts\"] = self.u_ng_ts.get_simple_td(uid, ts)\n",
    "        \n",
    "        uid, bid = ubid\n",
    "        if uid not in self.u_first_b.keys():\n",
    "            self.u_first_b[uid] = bid\n",
    "        output[\"u_first_b\"] = self.u_first_b[uid]\n",
    "        \n",
    "\n",
    "        data_list.append(output)\n",
    "        return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PocketFFUtil():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def merge(self, ff1, ff2):\n",
    "        counters = [\n",
    "            \"u_ac\", \"uc_ac\", \"u_qm\", \"u_ok_qm\", \"u_ng_qm\",\n",
    "            \"up_ac\", \"ulr_ac\", \"uca_ac\", \"ut_ac\",\n",
    "            \"u_rate\", \"u_nncl_ac\", \"ucl_ac\"\n",
    "        ]\n",
    "        for counter in counters:\n",
    "            c1 = getattr(ff1, counter)\n",
    "            c2 = getattr(ff2, counter)\n",
    "            c1.cnt.update(c2.cnt)\n",
    "            c1.sum.update(c2.sum)\n",
    "        \n",
    "        timestamps = [\n",
    "            \"u_ts\", \"uc_ts\", \"ul_ts\", \"u_ts_wl\"\n",
    "        ]\n",
    "        for timestamp in timestamps:\n",
    "            ts1 = getattr(ff1, timestamp)\n",
    "            ts2 = getattr(ff2, timestamp)\n",
    "            ts1.prev_ts.update(ts2.prev_ts)\n",
    "        \n",
    "        rolls = [\"u_ac_roll\", \"u_ts_roll\"]\n",
    "        for r in rolls:\n",
    "            r1 =  getattr(ff1, r)\n",
    "            r2 =  getattr(ff2, r)\n",
    "            r1.roll.update(r2.roll)\n",
    "            \n",
    "        rates = [\"u_elo\"]\n",
    "        for r in rates:\n",
    "            r1 = getattr(ff1, r)\n",
    "            r2 = getattr(ff2, r)\n",
    "            r1.u_theta.update(r2.u_theta)\n",
    "            r1.u_cnt.update(r2.u_cnt)\n",
    "        \n",
    "        return ff1\n",
    "        \n",
    "    def to_file(self, ff, suffix):\n",
    "        uid_set, uc_dict, ut_dict = self.make_ins_dict(ff)\n",
    "        \n",
    "        prefix = \"./temp_files\"\n",
    "        day = \"1223\"\n",
    "        \n",
    "        with h5py.File(f\"{prefix}/uc_dict_{day}_{suffix}.hdf5\", \"w\") as f:   \n",
    "            for (uid, l) in tqdm(uc_dict.items()):\n",
    "                f.create_dataset(str(uid), data=l)\n",
    "                \n",
    "        with h5py.File(f\"{prefix}/ut_dict_{day}_{suffix}.hdf5\", \"w\") as f:   \n",
    "            for (uid, l) in tqdm(ut_dict.items()):\n",
    "                f.create_dataset(str(uid), data=l)\n",
    "                \n",
    "#         with open(f\"./uid_set_1213_{suffix}.pkl\", \"wb\") as handle:\n",
    "#             pickle.dump(uid_set, handle, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        ff = self.del_filed_attributes(ff)\n",
    "        with open(f\"{prefix}/ff_{day}_{suffix}.pkl\", \"wb\") as handle:\n",
    "            pickle.dump(ff, handle, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def make_ins_dict(self, ff):\n",
    "        uid_set = set()\n",
    "        uc_dict, ut_dict = {}, {}\n",
    "        #print(len(ff.ub_ac), len(ff.ub_ts), len(ff.uc_ac), len(ff.uc_ts))\n",
    "        \n",
    "        for k, ts in tqdm(ff.uc_ts.prev_ts.items()):\n",
    "            (uid, cid) = k\n",
    "            l = uc_dict.get(uid, [])\n",
    "            ac_sum, ac_cnt = ff.uc_ac.sum.get(k, np.nan), ff.uc_ac.cnt.get(k, np.nan)\n",
    "            new_data = [cid, ts, ac_sum, ac_cnt]\n",
    "            l.append(new_data)\n",
    "            uc_dict[uid] = l\n",
    "            #uid_set.add(uid)\n",
    "        for k, ts in tqdm(ff.ut_ac.sum.items()):\n",
    "            (uid, tag) = k\n",
    "            l = ut_dict.get(uid, [])\n",
    "            ac_sum, ac_cnt = ff.ut_ac.sum.get(k, np.nan), ff.ut_ac.cnt.get(k, np.nan)\n",
    "            new_data = [int(tag), ac_sum, ac_cnt]\n",
    "            l.append(new_data)\n",
    "            ut_dict[uid] = l\n",
    "            #uid_set.add(uid)\n",
    "        return uid_set, uc_dict, ut_dict\n",
    "    \n",
    "    def del_filed_attributes(self, ff):\n",
    "        ff.uc_ac = PocketCounter()\n",
    "        ff.uc_ts = PocketTimestamp()\n",
    "        ff.ut_ac = PocketCounter()\n",
    "        return ff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_clusters = pd.read_csv(\"./content_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_train = train[train[\"answered_correctly\"] != -1].copy()\n",
    "# content_train[\"temp_uac\"] = content_train.groupby(\"user_id\")[\"answered_correctly\"].transform(\"mean\")\n",
    "# # content_train[\"td\"] = content_train.groupby(\"user_id\")[\"timestamp\"].diff()\n",
    "# # content_train[\"td\"] = content_train[\"timestamp\"] - content_train.groupby(\"user_id\")[\"timestamp\"].shift()\n",
    "# # content_train[\"td\"] = content_train.groupby([\"user_id\", \"task_container_id\"])[\"td\"].transform(\"max\")\n",
    "# # content_train[\"one\"] = 1\n",
    "# # content_train[\"temp_ucnt\"] = content_train.groupby(\"user_id\")[\"one\"].cumsum()\n",
    "# # content_train[\"temp_log_ucnt\"] = np.log1p(content_train[\"temp_ucnt\"])\n",
    "\n",
    "# q_col = [\"question_id\", \"bundle_id\"]\n",
    "# content_train = pd.merge(\n",
    "#     content_train, question[q_col], left_on=\"content_id\", right_on=\"question_id\", how=\"left\"\n",
    "# )\n",
    "\n",
    "# # contents features\n",
    "# # there are no new contents in the test, so we use part of the train as the pseudo-training set\n",
    "# temp = content_train.groupby(\"content_id\")[\"answered_correctly\"].agg([\"mean\", \"count\"])\n",
    "# temp.columns = [\"q_ac_mean\", \"q_ac_cnt\"]\n",
    "# temp2 = content_train.groupby(\"content_id\")[\"prior_question_elapsed_time\"].agg([\"mean\", \"count\", \"std\"])\n",
    "# temp2.columns = [\"q_et_mean\", \"q_et_cnt\", \"q_et_std\"]\n",
    "# # temp3 = content_train.groupby(\"content_id\")[\"td\"].agg([\"mean\", \"std\", \"min\", \"max\", \"skew\"])\n",
    "# # temp3.columns = [\"q_td_mean\", \"q_td_std\", \"q_td_min\", \"q_td_max\", \"q_td_skew\"]\n",
    "# temp4 = content_train.groupby(\"bundle_id\")[\"answered_correctly\"].agg([\"mean\", \"count\"])\n",
    "# temp4.columns = [\"b_ac_mean\", \"b_ac_cnt\"]\n",
    "\n",
    "# temp6 = content_train[content_train[\"answered_correctly\"]==1]\n",
    "# temp6 = temp6.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp6.columns = [\"q_ok_uac_mean\", \"q_ok_uac_std\"]\n",
    "\n",
    "# temp7 = content_train[content_train[\"answered_correctly\"]==0]\n",
    "# temp7 = temp7.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp7.columns = [\"q_ng_uac_mean\", \"q_ng_uac_std\"]\n",
    "\n",
    "# # temp8 = content_train.groupby(\"content_id\")[\"temp_ucnt\"].agg([\"mean\", \"std\", \"skew\"])\n",
    "# # temp8.columns = [\"q_ucnt_mean\", \"q_ucnt_std\", \"q_ucnt_skew\"]\n",
    "# # temp9 = content_train.groupby(\"content_id\")[\"temp_log_ucnt\"].agg([\"mean\", \"std\", \"skew\"])\n",
    "# # temp9.columns = [\"q_lucnt_mean\", \"q_lucnt_std\", \"q_lucnt_skew\"]\n",
    "# # temp10 = content_train[content_train[\"temp_ucnt\"]>10]\n",
    "# # temp10 = temp10.groupby(\"content_id\")[\"answered_correctly\"].agg([\"mean\"])\n",
    "# # temp10.columns = [\"q_ex10_mean\"]\n",
    "\n",
    "# temp11 = content_train[content_train[\"prior_question_had_explanation\"]==True]\n",
    "# temp11 = temp11.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp11.columns = [\"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\"]\n",
    "\n",
    "# temp12 = content_train[content_train[\"prior_question_had_explanation\"]==False]\n",
    "# temp12 = temp12.groupby(\"content_id\")[\"temp_uac\"].agg([\"mean\", \"std\"])\n",
    "# temp12.columns = [\"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\"]\n",
    "\n",
    "# temp13 = content_train.groupby(\"content_id\")[\"user_id\"].agg([\"nunique\", \"count\"])\n",
    "# temp13.columns = [\"q_u_nunique\", \"q_u_cnt\"]\n",
    "# temp13[\"q_u_unique_ratio\"] = temp13[\"q_u_nunique\"] / temp13[\"q_u_cnt\"]\n",
    "\n",
    "# # temp14 = content_train.groupby([\"content_id\", \"user_answer\"])[\"temp_uac\"].agg([\"count\", \"mean\"])\n",
    "# # temp14[\"count_sum\"] = temp14.groupby([\"content_id\"])[\"count\"].transform(\"sum\")\n",
    "# # temp14[\"cnt_ratio\"] = temp14[\"count\"] / temp14[\"count_sum\"]\n",
    "# # temp14.sort_values([\"content_id\", \"count\"], ascending=False, inplace=True)\n",
    "# # temp14[\"one\"] = 1\n",
    "# # temp14[\"ans_order\"] = temp14.groupby(\"content_id\")[\"one\"].cumsum()\n",
    "# # temp14 = temp14.reset_index().pivot(index=\"content_id\", columns=\"ans_order\", values=[\"mean\", \"cnt_ratio\"])\n",
    "# # temp14.columns =[f\"q_{s1}_ans{str(s2)}\" for (s1,s2) in temp14.columns.tolist()]\n",
    "\n",
    "# question[\"b_cnt\"] = question.groupby(\"bundle_id\")[\"question_id\"].transform(\"count\")\n",
    "# q_col = [\"question_id\", \"bundle_id\", \"part\", \"correct_answer\", \"tags\", \"b_cnt\"]\n",
    "# #q_col += [str(i) for i in range(188)]\n",
    "# contents = pd.merge(question[q_col], temp, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp2, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# # contents = pd.merge(contents, temp3, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp4, on=\"bundle_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp6, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp7, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# # contents = pd.merge(contents, temp8, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# # contents = pd.merge(contents, temp9, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# # contents = pd.merge(contents, temp10, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp11, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp12, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# contents = pd.merge(contents, temp13, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# #contents = pd.merge(contents, temp14, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "# print(contents.head(2))\n",
    "# print(contents.shape)\n",
    "# merge_col = [\n",
    "#     \"question_id\", \"bundle_id\", \"part\", \"correct_answer\", \"tags\",\n",
    "#     \"q_ac_mean\", \"q_ac_cnt\", \"q_et_mean\",\n",
    "#     \"q_et_cnt\", \"q_et_std\", \"b_ac_mean\", \"b_ac_cnt\",\n",
    "#     \"q_ok_uac_mean\", \"q_ok_uac_std\", \"q_ng_uac_mean\", \"q_ng_uac_std\",\n",
    "#     \"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\", \"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\",\n",
    "#     \"q_u_nunique\", \"q_u_cnt\", \"q_u_unique_ratio\",\n",
    "#     #\"q_mean_ans1\", \"q_mean_ans2\", \"q_mean_ans3\", \"q_mean_ans4\",\n",
    "#     #\"q_cnt_ratio_ans1\", \"q_cnt_ratio_ans2\", \"q_cnt_ratio_ans3\", \"q_cnt_ratio_ans4\",\n",
    "#     \"q_td_mean\", \"q_td_std\", \"q_td_min\", \"q_td_max\", \"q_td_skew\",\n",
    "#     #\"b_cnt\", \n",
    "# ]\n",
    "# contents = contents[merge_col]\n",
    "# contents[\"tags\"].fillna(\"-1\", inplace=True)\n",
    "\n",
    "# contents = pd.merge(contents, content_clusters, left_on=\"question_id\", right_on=\"content_id\", how=\"left\")\n",
    "\n",
    "# contents = contents.set_index(\"question_id\")\n",
    "# contents_dict = contents.to_dict(\"index\")\n",
    "# print(len(contents_dict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edq_df = pd.read_csv(\"./temp_merge.csv\")\n",
    "# edq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_col = [\"question_id\", \"count\", \"mean\", \"deployed_at\"]\n",
    "# contents_ed = pd.merge(contents, edq_df[merge_col], on=\"question_id\", how=\"left\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cols = contents_ed.columns\n",
    "# cols2 = list(cols)[:-3]\n",
    "# cols2 =  cols2 + [\"edq_count\", \"edq_mean\", \"deployed_at\"]\n",
    "# contents_ed.columns = cols2\n",
    "# contents_ed = contents_ed.set_index(\"question_id\")\n",
    "# contents_ed.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents_dict = contents_ed.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./contents_dict_full_1222.pkl\", \"wb\") as handle:\n",
    "#     pickle.dump(contents_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# print(len(contents_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13523\n"
     ]
    }
   ],
   "source": [
    "with open(\"./contents_dict_full_1223.pkl\", \"rb\") as handle:\n",
    "    contents_dict = pickle.load(handle)\n",
    "print(len(contents_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = pd.DataFrame.from_dict(contents_dict, orient=\"index\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>tags</th>\n",
       "      <th>q_ac_mean</th>\n",
       "      <th>q_ac_cnt</th>\n",
       "      <th>q_et_mean</th>\n",
       "      <th>q_et_cnt</th>\n",
       "      <th>q_et_std</th>\n",
       "      <th>...</th>\n",
       "      <th>nn_svd11</th>\n",
       "      <th>nn_svd12</th>\n",
       "      <th>nn_svd13</th>\n",
       "      <th>nn_svd14</th>\n",
       "      <th>nn_svd15</th>\n",
       "      <th>nn_svd16</th>\n",
       "      <th>nn_svd17</th>\n",
       "      <th>nn_svd18</th>\n",
       "      <th>nn_svd19</th>\n",
       "      <th>nn_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51 131 162 38</td>\n",
       "      <td>0.907721</td>\n",
       "      <td>6903</td>\n",
       "      <td>21875.328125</td>\n",
       "      <td>6901</td>\n",
       "      <td>10519.116289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>-0.019987</td>\n",
       "      <td>-0.051152</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.027400</td>\n",
       "      <td>-0.045768</td>\n",
       "      <td>-0.052895</td>\n",
       "      <td>-0.047862</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "      <td>0.890646</td>\n",
       "      <td>7398</td>\n",
       "      <td>22091.626953</td>\n",
       "      <td>7398</td>\n",
       "      <td>10867.885630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040753</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>0.045152</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>-0.058797</td>\n",
       "      <td>0.050018</td>\n",
       "      <td>-0.052557</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  bundle_id  part  correct_answer           tags  q_ac_mean  q_ac_cnt  \\\n",
       "0      0          0     1               0  51 131 162 38   0.907721      6903   \n",
       "1      1          1     1               1      131 36 81   0.890646      7398   \n",
       "\n",
       "      q_et_mean  q_et_cnt      q_et_std  ...  nn_svd11  nn_svd12  nn_svd13  \\\n",
       "0  21875.328125      6901  10519.116289  ...  0.044373 -0.019987 -0.051152   \n",
       "1  22091.626953      7398  10867.885630  ... -0.040753 -0.010178  0.045152   \n",
       "\n",
       "   nn_svd14  nn_svd15  nn_svd16  nn_svd17  nn_svd18  nn_svd19  nn_cluster  \n",
       "0  0.002223 -0.027400 -0.045768 -0.052895 -0.047862  0.010022         6.0  \n",
       "1  0.017016  0.018646 -0.058797  0.050018 -0.052557  0.025437         6.0  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_train = train[train[\"answered_correctly\"] != -1].copy()\n",
    "temp_content = content_train.groupby(\"content_id\")[\"prior_question_had_explanation\"].agg([\"mean\"])\n",
    "temp_content.columns = [\"pqhe_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pqhe_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pqhe_mean\n",
       "content_id           \n",
       "0            0.947849\n",
       "1            0.980400"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_content.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = pd.merge(contents, temp_content, left_on=\"index\", right_on=\"content_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>tags</th>\n",
       "      <th>q_ac_mean</th>\n",
       "      <th>q_ac_cnt</th>\n",
       "      <th>q_et_mean</th>\n",
       "      <th>q_et_cnt</th>\n",
       "      <th>q_et_std</th>\n",
       "      <th>...</th>\n",
       "      <th>nn_svd12</th>\n",
       "      <th>nn_svd13</th>\n",
       "      <th>nn_svd14</th>\n",
       "      <th>nn_svd15</th>\n",
       "      <th>nn_svd16</th>\n",
       "      <th>nn_svd17</th>\n",
       "      <th>nn_svd18</th>\n",
       "      <th>nn_svd19</th>\n",
       "      <th>nn_cluster</th>\n",
       "      <th>pqhe_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51 131 162 38</td>\n",
       "      <td>0.907721</td>\n",
       "      <td>6903</td>\n",
       "      <td>21875.328125</td>\n",
       "      <td>6901</td>\n",
       "      <td>10519.116289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019987</td>\n",
       "      <td>-0.051152</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-0.027400</td>\n",
       "      <td>-0.045768</td>\n",
       "      <td>-0.052895</td>\n",
       "      <td>-0.047862</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.947849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131 36 81</td>\n",
       "      <td>0.890646</td>\n",
       "      <td>7398</td>\n",
       "      <td>22091.626953</td>\n",
       "      <td>7398</td>\n",
       "      <td>10867.885630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010178</td>\n",
       "      <td>0.045152</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>-0.058797</td>\n",
       "      <td>0.050018</td>\n",
       "      <td>-0.052557</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.980400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  bundle_id  part  correct_answer           tags  q_ac_mean  q_ac_cnt  \\\n",
       "0      0          0     1               0  51 131 162 38   0.907721      6903   \n",
       "1      1          1     1               1      131 36 81   0.890646      7398   \n",
       "\n",
       "      q_et_mean  q_et_cnt      q_et_std  ...  nn_svd12  nn_svd13  nn_svd14  \\\n",
       "0  21875.328125      6901  10519.116289  ... -0.019987 -0.051152  0.002223   \n",
       "1  22091.626953      7398  10867.885630  ... -0.010178  0.045152  0.017016   \n",
       "\n",
       "   nn_svd15  nn_svd16  nn_svd17  nn_svd18  nn_svd19  nn_cluster  pqhe_mean  \n",
       "0 -0.027400 -0.045768 -0.052895 -0.047862  0.010022         6.0   0.947849  \n",
       "1  0.018646 -0.058797  0.050018 -0.052557  0.025437         6.0   0.980400  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_dict = contents.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 9, 'bundle_id': 9, 'part': 1, 'correct_answer': 3, 'tags': '10 164 81', 'q_ac_mean': 0.30391162928230475, 'q_ac_cnt': 47346, 'q_et_mean': 23491.630859375, 'q_et_cnt': 47342, 'q_et_std': 12454.050361085152, 'b_ac_mean': 0.30391162928230475, 'b_ac_cnt': 47346, 'q_ok_uac_mean': 0.6857515431448181, 'q_ok_uac_std': 0.10116188677769661, 'q_ng_uac_mean': 0.6489013139483224, 'q_ng_uac_std': 0.10784529549718692, 'q_pqhe_true_uac_mean': 0.6611712633318108, 'q_pqhe_true_uac_std': 0.10627594250298951, 'q_pqhe_false_uac_mean': 0.6301651008839987, 'q_pqhe_false_uac_std': 0.12698768426567777, 'q_u_nunique': 35147, 'q_u_cnt': 47346, 'q_u_unique_ratio': 0.7423435981920331, 'q_td_mean': 49674759.62025263, 'q_td_std': 903739661.796538, 'q_td_min': 3.0, 'q_td_max': 62720117332.0, 'q_td_skew': 35.82434020981072, 'content_id': 9, 'content_cluster': 25, 'elo_beta': 3.2318669150064028, 'nn_svd0': -0.4023511, 'nn_svd1': 0.09589093, 'nn_svd2': -0.023496637, 'nn_svd3': 0.18943904, 'nn_svd4': 0.06504166, 'nn_svd5': 0.19372135, 'nn_svd6': -0.015886473999999998, 'nn_svd7': 0.19471914, 'nn_svd8': 0.017754251000000002, 'nn_svd9': 0.076361716, 'nn_svd10': -0.013634813999999999, 'nn_svd11': 0.068157494, 'nn_svd12': -0.022096405, 'nn_svd13': 0.12180817, 'nn_svd14': 0.097399525, 'nn_svd15': 0.05045525, 'nn_svd16': -0.04606442, 'nn_svd17': -0.06922391, 'nn_svd18': 0.017103683, 'nn_svd19': 0.02962321, 'nn_cluster': 6.0, 'pqhe_mean': 0.9654669877075149}\n"
     ]
    }
   ],
   "source": [
    "print(contents_dict[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./elo-item.pkl\", \"rb\") as handle:\n",
    "#     elo_item = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in contents_dict.items():\n",
    "#     contents_dict[k][\"elo_beta\"] = elo_item[k][\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents_vec = pd.read_csv(\"./content_nn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents_vec.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in contents_vec.values:\n",
    "#     cid = row[0]\n",
    "#     for j in range(20):\n",
    "#         contents_dict[cid][f\"nn_svd{j}\"] = row[j+1]\n",
    "#     contents_dict[cid][\"nn_cluster\"] = row[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(contents_dict[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./contents_dict_full_1223.pkl\", \"wb\") as handle:\n",
    "#     pickle.dump(contents_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# print(len(contents_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101230332\n"
     ]
    }
   ],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLgb:\n",
    "    def __init__(self, seed=99, dry_run=False):\n",
    "        self.train_param = self.get_param()\n",
    "        if dry_run:\n",
    "            self.num_rounds = 100\n",
    "        else:\n",
    "            self.num_rounds = 500\n",
    "\n",
    "    def do_train_direct(self, x_train, x_test, y_train, y_test):\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "        # print('Start training...')\n",
    "        model = lgb.train(self.train_param,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_eval],\n",
    "                          verbose_eval=100,\n",
    "                          num_boost_round=self.num_rounds,\n",
    "                          early_stopping_rounds=100,\n",
    "                          #categorical_feature=[]\n",
    "                         )\n",
    "        # print('End training...')\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def show_feature_importance(model, filename=None):\n",
    "        fi = pd.DataFrame({\n",
    "            \"name\": model.feature_name(),\n",
    "            \"importance_split\": model.feature_importance(importance_type=\"split\").astype(int),\n",
    "            \"importance_gain\": model.feature_importance(importance_type=\"gain\").astype(int),\n",
    "        })\n",
    "        fi = fi.sort_values(by=\"importance_gain\", ascending=False)\n",
    "        #print(fi)\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            print(fi)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_param():\n",
    "        return {\n",
    "            'num_leaves': 1023,\n",
    "            'min_data_in_leaf': 100,\n",
    "            'objective': 'binary',\n",
    "            #'metric': 'auc',\n",
    "            'metric': 'binary_logloss',\n",
    "            'max_depth': -1,\n",
    "            'learning_rate': 0.1,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 0.9,\n",
    "            \"verbosity\": -1,\n",
    "            \"random_state\": 81,\n",
    "        }\n",
    "    \n",
    "class SingleTrainer:\n",
    "    def __init__(self, pred_col, dry_run=False):\n",
    "        self.pred_col = pred_col\n",
    "        self.target_col = \"ac\"\n",
    "        self.dry_run = dry_run\n",
    "        self.val_size = 5*1000*1000\n",
    "\n",
    "    def train_model(self, df):\n",
    "        X = df[self.pred_col]\n",
    "        y = df[self.target_col]\n",
    "        \n",
    "        models, scores = list(), list()\n",
    "        for fold in range(4):\n",
    "            print(\"---------\")\n",
    "            print(\"fold=\", fold)\n",
    "            f, c = fold, self.val_size\n",
    "            val_s, val_e = -c-f*c, len(df)-f*c\n",
    "            train_idx = -c-f*c\n",
    "            X_train, X_val = X.iloc[:train_idx], X.iloc[val_s:val_e]\n",
    "            y_train, y_val = y.iloc[:train_idx], y.iloc[val_s:val_e]\n",
    "            print(X_train.shape, X_val.shape)\n",
    "            \n",
    "            lgbm = SingleLgb(seed=99, dry_run=self.dry_run)\n",
    "            model = lgbm.do_train_direct(X_train, X_val, y_train, y_val)\n",
    "            score = model.best_score[\"valid_0\"][\"binary_logloss\"]\n",
    "            pred = model.predict(X_val)\n",
    "            score = metrics.roc_auc_score(y_val, pred)\n",
    "            print(\"AUC=\", score)\n",
    "            if fold == 0:\n",
    "                lgbm.show_feature_importance(model)\n",
    "            models.append(model)\n",
    "            scores.append(score)\n",
    "            break\n",
    "        return models, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_list = list()\n",
    "# utcid_set = set()\n",
    "# prev_rows, prev_acs, prev_uas = list(), list(), list()\n",
    "# #init_values()\n",
    "\n",
    "# not_updated_idx = 0\n",
    "# for i, row in enumerate(tqdm(train.values)):\n",
    "# #     if i < 56597670:\n",
    "# #         continue\n",
    "# #     if i > 56597680:\n",
    "# #         break\n",
    "#     uid = row[2]\n",
    "#     tcid = row[5]\n",
    "#     utcid = (uid, tcid)\n",
    "#     if utcid not in utcid_set:\n",
    "#         if len(prev_rows) > 0:\n",
    "#             update_ac_values(prev_rows, prev_acs, prev_uas)\n",
    "#             prev_rows.clear()\n",
    "#             prev_acs.clear()\n",
    "#             prev_uas.clear()\n",
    "#             utcid_set.clear()\n",
    "#             not_updated_idx = i\n",
    "#     prev_rows.append(row)\n",
    "#     prev_acs.append(row[7])\n",
    "#     prev_uas.append(row[6])\n",
    "#     utcid_set.add(utcid)\n",
    "        \n",
    "#     make_row(row, train_data_list, True)\n",
    "        \n",
    "\n",
    "# start_time = time.time()\n",
    "# df = pd.DataFrame(train_data_list)\n",
    "# end_time = time.time()\n",
    "# print(end_time - start_time)\n",
    "# print(df.head(2))\n",
    "# #print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'user_answer', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"uid_mod\"] = train[\"user_id\"] % 37\n",
    "train = train[train[\"uid_mod\"] < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3407861\n",
      "74.71563076972961\n",
      "3384677\n",
      "154.44342827796936\n",
      "3531723\n",
      "237.824294090271\n",
      "3507610\n",
      "320.8567478656769\n",
      "328.7668058872223\n"
     ]
    }
   ],
   "source": [
    "def get_row(train_):\n",
    "    ff = PocketFeatureFactory(True, contents_dict)\n",
    "    train_data_list = list()\n",
    "    utcid_set = set()\n",
    "    prev_rows, prev_acs, prev_uas = list(), list(), list()\n",
    "\n",
    "    for i, row in enumerate(train_.values):\n",
    "        ctype = row[4]\n",
    "        if ctype == 1:\n",
    "            ff.do_lecture(row)\n",
    "            continue\n",
    "        uid = row[2]\n",
    "        tcid = row[5]\n",
    "        utcid = (uid, tcid)\n",
    "        if utcid not in utcid_set:\n",
    "            if len(prev_rows) > 0:\n",
    "                #prev_df2 = train.iloc[not_updated_idx:i] iloc too slow lol\n",
    "                ff.update_ac_values(prev_rows, prev_acs, prev_uas)\n",
    "                prev_rows.clear()\n",
    "                prev_acs.clear()\n",
    "                prev_uas.clear()\n",
    "                utcid_set.clear()\n",
    "                \n",
    "        prev_rows.append(row)\n",
    "        prev_acs.append(row[7])\n",
    "        prev_uas.append(row[6])\n",
    "        utcid_set.add(utcid)\n",
    "\n",
    "        ff.make_row(row, train_data_list)\n",
    "    ff.update_ac_values(prev_rows, prev_acs, prev_uas)\n",
    "    \n",
    "    #return train_data_list\n",
    "    ret_idx = train_[train_[\"content_type_id\"]!=1].index\n",
    "    ret_df = pd.DataFrame(train_data_list)\n",
    "    ret_df.index = ret_idx\n",
    "    \n",
    "    return ret_df, ff\n",
    "\n",
    "start_time = time.time()\n",
    "SPLIT_NUM = 48\n",
    "USE_FROM = 4\n",
    "\n",
    "train[\"uid_mod\"] = train[\"user_id\"] % (USE_FROM)\n",
    "train[\"uid_mod2\"] = train[\"user_id\"] % (SPLIT_NUM)\n",
    "\n",
    "df_list = list()\n",
    "for i in range(USE_FROM):\n",
    "    sliced_train = train[train[\"uid_mod\"] == i]\n",
    "    print(len(sliced_train))\n",
    "\n",
    "    split_series = list()\n",
    "    for j in range(0, SPLIT_NUM):\n",
    "        one_split = sliced_train[sliced_train[\"uid_mod2\"] == j]\n",
    "        split_series.append(one_split)\n",
    "\n",
    "    future_list = list()\n",
    "    with futures.ProcessPoolExecutor(max_workers=SPLIT_NUM) as executor:\n",
    "        for s in split_series:\n",
    "            future_list.append(executor.submit(get_row, s))\n",
    "    future_results = [f.result() for f in future_list]\n",
    "    end_time = time.time()\n",
    "    print(end_time - start_time)\n",
    "    df_futures = [f[0] for f in future_results]\n",
    "    ff_futures = [f[1] for f in future_results]\n",
    "    \n",
    "    df = pd.concat(df_futures)\n",
    "    df_list.append(df)\n",
    "    \n",
    "#     utils = PocketFFUtil()\n",
    "#     conc_ff = ff_futures[0]\n",
    "#     for j in range(len(ff_futures)-1):\n",
    "#         conc_ff = utils.merge(conc_ff, ff_futures[j+1])\n",
    "        \n",
    "#     utils.to_file(conc_ff, i)\n",
    "#     del conc_ff\n",
    "#     del ff_futures\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13563412, 72)\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.concat(df_list)\n",
    "print(final_df.shape)\n",
    "sorted_df = final_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ac</th>\n",
       "      <th>et</th>\n",
       "      <th>q_ac_mean</th>\n",
       "      <th>q_ac_cnt</th>\n",
       "      <th>q_et_mean</th>\n",
       "      <th>q_et_cnt</th>\n",
       "      <th>q_et_std</th>\n",
       "      <th>b_ac_mean</th>\n",
       "      <th>b_ac_cnt</th>\n",
       "      <th>part</th>\n",
       "      <th>...</th>\n",
       "      <th>u_td_p4p5</th>\n",
       "      <th>u_td_p5p6</th>\n",
       "      <th>u_td_p6p7</th>\n",
       "      <th>u_td_p7p8</th>\n",
       "      <th>u_td_p8p9</th>\n",
       "      <th>u_td_p9p10</th>\n",
       "      <th>ut_ac_mean</th>\n",
       "      <th>ut_ac_mean2</th>\n",
       "      <th>u_ng_ts</th>\n",
       "      <th>u_first_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.472588</td>\n",
       "      <td>29093</td>\n",
       "      <td>24814.373047</td>\n",
       "      <td>29025</td>\n",
       "      <td>21623.967618</td>\n",
       "      <td>0.472588</td>\n",
       "      <td>29093</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>17518</td>\n",
       "      <td>25315.376953</td>\n",
       "      <td>17434</td>\n",
       "      <td>22030.881659</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>17518</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12518.0</td>\n",
       "      <td>6125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ac       et  q_ac_mean  q_ac_cnt     q_et_mean  q_et_cnt      q_et_std  \\\n",
       "11  0.0      NaN   0.472588     29093  24814.373047     29025  21623.967618   \n",
       "13  1.0  23000.0   0.762016     17518  25315.376953     17434  22030.881659   \n",
       "\n",
       "    b_ac_mean  b_ac_cnt  part  ...  u_td_p4p5  u_td_p5p6  u_td_p6p7  \\\n",
       "11   0.472588     29093     5  ...        NaN        NaN        NaN   \n",
       "13   0.762016     17518     5  ...        NaN        NaN        NaN   \n",
       "\n",
       "    u_td_p7p8  u_td_p8p9  u_td_p9p10  ut_ac_mean  ut_ac_mean2  u_ng_ts  \\\n",
       "11        NaN        NaN         NaN         NaN          NaN      NaN   \n",
       "13        NaN        NaN         NaN         NaN          NaN -12518.0   \n",
       "\n",
       "    u_first_b  \n",
       "11       6125  \n",
       "13       6125  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "del final_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# df = pd.DataFrame(data_list)\n",
    "# 24.7 s ± 205 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ac</th>\n",
       "      <th>et</th>\n",
       "      <th>q_ac_mean</th>\n",
       "      <th>q_ac_cnt</th>\n",
       "      <th>q_et_mean</th>\n",
       "      <th>q_et_cnt</th>\n",
       "      <th>q_et_std</th>\n",
       "      <th>b_ac_mean</th>\n",
       "      <th>b_ac_cnt</th>\n",
       "      <th>part</th>\n",
       "      <th>...</th>\n",
       "      <th>u_td_p3p4</th>\n",
       "      <th>u_td_p4p5</th>\n",
       "      <th>u_td_p5p6</th>\n",
       "      <th>u_td_p6p7</th>\n",
       "      <th>u_td_p7p8</th>\n",
       "      <th>u_td_p8p9</th>\n",
       "      <th>u_td_p9p10</th>\n",
       "      <th>ut_ac_mean</th>\n",
       "      <th>ut_ac_mean2</th>\n",
       "      <th>u_first_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654389</td>\n",
       "      <td>1629</td>\n",
       "      <td>25343.691406</td>\n",
       "      <td>1567</td>\n",
       "      <td>25751.13389</td>\n",
       "      <td>0.654389</td>\n",
       "      <td>1629</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>0.850819</td>\n",
       "      <td>11114</td>\n",
       "      <td>18633.333984</td>\n",
       "      <td>11113</td>\n",
       "      <td>10146.27939</td>\n",
       "      <td>0.850819</td>\n",
       "      <td>11114</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ac       et  q_ac_mean  q_ac_cnt     q_et_mean  q_et_cnt     q_et_std  \\\n",
       "4543  1.0      NaN   0.654389      1629  25343.691406      1567  25751.13389   \n",
       "4548  1.0  22000.0   0.850819     11114  18633.333984     11113  10146.27939   \n",
       "\n",
       "      b_ac_mean  b_ac_cnt  part  ...  u_td_p3p4  u_td_p4p5  u_td_p5p6  \\\n",
       "4543   0.654389      1629     5  ...        NaN        NaN        NaN   \n",
       "4548   0.850819     11114     2  ...        NaN        NaN        NaN   \n",
       "\n",
       "      u_td_p6p7  u_td_p7p8  u_td_p8p9  u_td_p9p10  ut_ac_mean  ut_ac_mean2  \\\n",
       "4543        NaN        NaN        NaN         NaN         NaN          NaN   \n",
       "4548        NaN        NaN        NaN         NaN         NaN          NaN   \n",
       "\n",
       "      u_first_b  \n",
       "4543       3806  \n",
       "4548       3806  \n",
       "\n",
       "[2 rows x 74 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_feather(\"./temp_df.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ac', 'et', 'q_ac_mean', 'q_ac_cnt', 'q_et_mean', 'q_et_cnt',\n",
       "       'q_et_std', 'b_ac_mean', 'b_ac_cnt', 'part', 'correct_answer',\n",
       "       'q_ok_uac_mean', 'q_ok_uac_std', 'q_ng_uac_mean', 'q_ng_uac_std',\n",
       "       'q_pqhe_true_uac_mean', 'q_pqhe_true_uac_std', 'q_pqhe_false_uac_mean',\n",
       "       'q_pqhe_false_uac_std', 'elo_beta', 'nn_svd0', 'nn_svd1', 'nn_svd2',\n",
       "       'nn_svd3', 'nn_svd4', 'nn_svd5', 'nn_svd6', 'nn_svd7', 'nn_svd8',\n",
       "       'nn_svd9', 'nn_svd10', 'nn_svd11', 'nn_svd12', 'nn_svd13', 'nn_svd14',\n",
       "       'nn_svd15', 'nn_svd16', 'nn_svd17', 'nn_svd18', 'nn_svd19', 'u_td',\n",
       "       'uc_td', 'u_td_wl', 'ul_td', 'u_cnt', 'u_ac_cnt', 'u_ac_mean',\n",
       "       'uc_ac_cnt', 'uc_ac_mean', 'uca_ac_mean', 'u_qm_mean', 'up_ac_cnt',\n",
       "       'up_ac_mean', 'ulr_ac_mean', 'u_ok_qm_mean', 'u_ng_qm_mean',\n",
       "       'u_ac_mean20', 'u_rate', 'u_elo_theta', 'uac_prev1', 'uac_prev2',\n",
       "       'u_td_tp1', 'u_td_p1p2', 'u_td_p2p3', 'u_td_p3p4', 'u_td_p4p5',\n",
       "       'u_td_p5p6', 'u_td_p6p7', 'u_td_p7p8', 'u_td_p8p9', 'u_td_p9p10',\n",
       "       'ut_ac_mean', 'ut_ac_mean2', 'u_first_b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# temp_df = df.sort_index()\n",
    "# print(temp_df.head())\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_feather(\"./temp_df.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['et', 'q_ac_cnt', 'b_ac_mean', 'b_ac_cnt', 'q_ac_mean', 'u_ac_mean', 'u_cnt', 'u_qm_mean', 'u_ac_cnt', 'u_ok_qm_mean', 'u_ng_qm_mean', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'up_ac_cnt', 'up_ac_mean', 'u_td', 'q_ng_uac_mean', 'q_ok_uac_mean', 'q_ok_uac_std', 'q_ng_uac_std', 'correct_answer', 'u_ac_mean20', 'ulr_ac_mean', 'ut_ac_mean', 'ut_ac_mean2', 'uca_ac_mean', 'ul_td', 'u_td_wl', 'uc_td', 'uc_ac_mean', 'uc_ac_cnt', 'u_td_tp1', 'u_td_p1p2', 'u_td_p2p3', 'u_td_p3p4', 'u_td_p4p5', 'u_td_p5p6', 'u_td_p6p7', 'u_td_p7p8', 'u_td_p8p9', 'u_td_p9p10', 'uac_prev1', 'uac_prev2', 'elo_beta', 'u_elo_theta', 'u_rate', 'u_ng_ts', 'pqhe_mean']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_col = [\n",
    "    \"et\",  \"q_ac_cnt\",  'b_ac_mean', 'b_ac_cnt', \"q_ac_mean\",\n",
    "    \"u_ac_mean\", \"u_cnt\", \"u_qm_mean\", #\"u_td\", #\"uc_td\",\n",
    "    \"u_ac_cnt\", #\"u_et_cnt\"\n",
    "    'u_ok_qm_mean', 'u_ng_qm_mean',\n",
    "    'q_et_mean', 'q_et_cnt', 'q_et_std',\n",
    "   \"up_ac_cnt\", \"up_ac_mean\",\n",
    "    \"u_td\", \n",
    "    \"q_ng_uac_mean\",\"q_ok_uac_mean\", \"q_ok_uac_std\", \"q_ng_uac_std\",\n",
    "    \"correct_answer\",\n",
    "    \"u_ac_mean20\",\n",
    "    \"ulr_ac_mean\", #\"ulr_ac_cnt\",  \"ub_cnt\",\n",
    "    \"ut_ac_mean\",\"ut_ac_mean2\",\n",
    "    \"uca_ac_mean\", \n",
    "    \"ul_td\", \"u_td_wl\", \n",
    "    #\"q_pqhe_true_uac_mean\", \"q_pqhe_true_uac_std\", \"q_pqhe_false_uac_mean\", \"q_pqhe_false_uac_std\",\n",
    "    #\"pqhe\",\n",
    "    \"uc_td\", \"uc_ac_mean\", \"uc_ac_cnt\", \n",
    "    #\"u_td_final\", #\"ub_td_final\"\n",
    "    'u_td_tp1','u_td_p1p2', 'u_td_p2p3', 'u_td_p3p4', 'u_td_p4p5',\n",
    "    'u_td_p5p6', 'u_td_p6p7', 'u_td_p7p8', 'u_td_p8p9', 'u_td_p9p10',\n",
    "    \"uac_prev1\", \"uac_prev2\",\n",
    "    #\"ucl_ac_mean\",\n",
    "    \"elo_beta\", \"u_elo_theta\", \n",
    "    \"u_rate\",\n",
    "]\n",
    "new_col = [\n",
    "    #\"u_nncl_ac_mean\"\n",
    "    #\"u_first_b\"\n",
    "    \"u_ng_ts\", \"pqhe_mean\"\n",
    "]\n",
    "nn_col = [f\"nn_svd{i}\" for i in range(20)]\n",
    "pred_col += new_col\n",
    "#pred_col += nn_col\n",
    "print(pred_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[new_col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# light_col = [\n",
    "#     'q_ac_mean', 'q_ac_cnt', 'q_et_mean', 'q_et_cnt', 'q_et_std', 'b_ac_mean', 'b_ac_cnt',\n",
    "#     'u_cnt', 'u_qm_mean', 'u_ac_mean', 'et', \"ub_td2\"\n",
    "# ]\n",
    "# new_light_col = [\n",
    "#     'u_ok_qm_mean', 'u_ng_qm_mean',\n",
    "#     \"up_ac_mean\", \"uca_ac_mean\", #\"u_ac_mean20\", \n",
    "#     #\"ut_ac_mean\", \"ut_ac_mean2\",\n",
    "#     \"q_ng_uac_mean\",\"q_ok_uac_mean\", \n",
    "#     \"u_td2\", \n",
    "#     #\"ub_cnt\", \"ubb_cnt\",\n",
    "#     #\"up_ac_cnt\", \"u_ac_cnt\",\n",
    "#     \"correct_answer\", \"ulr_ac_mean\"\n",
    "# ]\n",
    "#pred_col = light_col + new_light_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "fold= 0\n",
      "(8563412, 49) (5000000, 49)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.511564\n",
      "[200]\tvalid_0's binary_logloss: 0.510955\n",
      "[300]\tvalid_0's binary_logloss: 0.511135\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's binary_logloss: 0.510938\n",
      "AUC= 0.7957140972948046\n",
      "              name  importance_split  importance_gain\n",
      "4        q_ac_mean              3173          4975377\n",
      "45     u_elo_theta              5824          2217629\n",
      "44        elo_beta              4085          1605536\n",
      "29           uc_td              4910           813661\n",
      "28         u_td_wl              6139           348004\n",
      "15      up_ac_mean              5591           249137\n",
      "33       u_td_p1p2              8181           247965\n",
      "16            u_td              6505           247712\n",
      "17   q_ng_uac_mean              7269           246106\n",
      "32        u_td_tp1              5106           179516\n",
      "2        b_ac_mean              3627           158658\n",
      "18   q_ok_uac_mean              5840           155216\n",
      "47         u_ng_ts              5740           135844\n",
      "10    u_ng_qm_mean              5242           123927\n",
      "30      uc_ac_mean              1459           122849\n",
      "27           ul_td              6495           117171\n",
      "23     ulr_ac_mean              4288           115179\n",
      "0               et              5114           108828\n",
      "11       q_et_mean              5250           107478\n",
      "19    q_ok_uac_std              5294           104243\n",
      "20    q_ng_uac_std              5529            97729\n",
      "34       u_td_p2p3              5655            97210\n",
      "35       u_td_p3p4              5514            89761\n",
      "46          u_rate              5006            86767\n",
      "13        q_et_std              4489            81319\n",
      "14       up_ac_cnt              5002            78739\n",
      "36       u_td_p4p5              5157            75551\n",
      "41      u_td_p9p10              5160            73949\n",
      "37       u_td_p5p6              4734            71409\n",
      "24      ut_ac_mean              3777            70470\n",
      "48       pqhe_mean              4395            70460\n",
      "26     uca_ac_mean              4546            68065\n",
      "40       u_td_p8p9              4729            67162\n",
      "39       u_td_p7p8              4800            66624\n",
      "38       u_td_p6p7              4669            66463\n",
      "25     ut_ac_mean2              3757            66308\n",
      "9     u_ok_qm_mean              4389            61491\n",
      "5        u_ac_mean              3849            56176\n",
      "1         q_ac_cnt              2970            54589\n",
      "3         b_ac_cnt              3073            50127\n",
      "6            u_cnt              3141            49087\n",
      "7        u_qm_mean              3466            45482\n",
      "8         u_ac_cnt              2476            40298\n",
      "22     u_ac_mean20              2161            35707\n",
      "12        q_et_cnt              1633            25252\n",
      "21  correct_answer              1185            23601\n",
      "31       uc_ac_cnt               474            15552\n",
      "43       uac_prev2               381             8787\n",
      "42       uac_prev1               305             5555\n"
     ]
    }
   ],
   "source": [
    "#temp_df = df[1*1000*1000:].copy()\n",
    "#temp_df = df.copy()\n",
    "trainer = SingleTrainer(pred_col, dry_run=False)\n",
    "models, score = trainer.train_model(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without new cols = 0.7908\n",
    "#first try =0.7942\n",
    "#more tds = 0.7950\n",
    "# svd20 79929\n",
    "# svd10 79899\n",
    "# svd15 79913\n",
    "# 15with target-encode 79923\n",
    "# 20with target-encode 79926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#standard way\n",
    "#[1000]\tvalid_0's auc: 0.782993\n",
    "\n",
    "#periodic initialization\n",
    "#0.730-2\n",
    "\n",
    "#with u_ac_mean\n",
    "#0.762\n",
    "\n",
    "#with uc_td\n",
    "#has 0.776ish\n",
    "\n",
    "#with U_et_cnt(reset-cnt)\n",
    "#same\n",
    "\n",
    "#with uc_ac_prev\n",
    "#0.777ish\n",
    "\n",
    "#without\n",
    "#[1000]\tvalid_0's auc: 0.765165\n",
    "\n",
    "# with full row  feature\n",
    "#[1000]\tvalid_0's auc: 0.765111\n",
    "\n",
    "# with full cdict\n",
    "#[1000]\tvalid_0's auc: 0.765448\n",
    "\n",
    "# dropping td by //10*1000 decrease score by 0.001\n",
    "\n",
    "# new feats from test_features=0.785 ->?0.7897\n",
    "\n",
    "# add lots of features =0.79299\n",
    "\n",
    "# add more feats = 0.7876-> 0.7895\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7fe47ffecd50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].save_model(\"./model_1223.lgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031794595060107\n"
     ]
    }
   ],
   "source": [
    "final_valid = sorted_df.iloc[-5*1000*1000:]\n",
    "pred_y = models[0].predict(final_valid[pred_col])\n",
    "score = metrics.roc_auc_score(final_valid[\"ac\"], pred_y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output = pd.DataFrame(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_y).to_csv(\"./pred_1223.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_valid.reset_index().to_feather(\"./valid_1223.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
